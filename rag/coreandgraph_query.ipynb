{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45492c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.12.8)\n",
      "Requirement already satisfied: llama-index-readers-obsidian in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: ipywidgets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (8.1.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: ipython in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (8.18.1)\n",
      "Requirement already satisfied: huggingface-hub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.24.0)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (1.58.1)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (6.0.1)\n",
      "Requirement already satisfied: llama-index-llms-ollama in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (0.5.0)\n",
      "Requirement already satisfied: llama-index-embeddings-ollama in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.5.0)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: ipykernel in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (6.27.1)\n",
      "Requirement already satisfied: pyvis in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (0.3.2)\n",
      "Requirement already satisfied: python-dotenv in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from -r requirements.txt (line 14)) (1.0.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.12.8)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.12)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (3.9.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (5.14.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: decorator in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython->-r requirements.txt (line 5)) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython->-r requirements.txt (line 5)) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython->-r requirements.txt (line 5)) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython->-r requirements.txt (line 5)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython->-r requirements.txt (line 5)) (4.9.0)\n",
      "Requirement already satisfied: filelock in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 7)) (4.1.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 7)) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 7)) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from openai->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: ollama>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-llms-ollama->-r requirements.txt (line 9)) (0.4.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.3.1)\n",
      "Requirement already satisfied: appnope in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (5.5.0)\n",
      "Requirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (1.5.8)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (5.9.6)\n",
      "Requirement already satisfied: pyzmq>=20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (6.4)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyvis->-r requirements.txt (line 13)) (3.1.4)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyvis->-r requirements.txt (line 13)) (3.2.2)\n",
      "Requirement already satisfied: networkx>=1.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyvis->-r requirements.txt (line 13)) (3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 7)) (3.6)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.11.11)\n",
      "Requirement already satisfied: minijinja>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.5.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from jinja2>=2.9.6->pyvis->-r requirements.txt (line 13)) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 12)) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 12)) (4.1.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (2.0.32)\n",
      "Requirement already satisfied: dataclasses-json in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.24.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (10.2.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (1.5.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.5.18)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (2023.8.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from pexpect>4.3->ipython->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->-r requirements.txt (line 5)) (0.2.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub->-r requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (4.42.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: scipy in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.11.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.18.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from asttokens>=2.1.0->stack-data->ipython->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: sympy in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.12)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (3.23.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.5.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "614fc4e2-0e04-49b0-bf7c-05efee48933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.obsidian import ObsidianReader\n",
    "from llama_index.core.memory.chat_memory_buffer import MessageRole\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex, VectorStoreIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import Document, PropertyGraphIndex\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "import logging\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    SimpleLLMPathExtractor,\n",
    "    SchemaLLMPathExtractor,\n",
    "    DynamicLLMPathExtractor,\n",
    ")\n",
    "import yaml\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5e9f925-0bd9-406c-a41d-8be268260b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    load_indices_from_storage,\n",
    "    load_graph_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8291822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17dd9f9d-7e21-49ef-9a01-d8b0dd7fdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9954a1",
   "metadata": {},
   "source": [
    "# Set LLM (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a66b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Charge les variables depuis le fichier .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY_UP\")\n",
    "# Modifier ou ajouter une variable d'environnement\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f9e96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-4o\", max_tokens=3000)\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d7bc2",
   "metadata": {},
   "source": [
    "# Set local LLM for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa4bc549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "#Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a4b82",
   "metadata": {},
   "source": [
    "# Set LLM for chat  (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d46a1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = Ollama(model=\"tinyllama\", request_timeout=120.0)\n",
    "#Settings.llm = llm\n",
    "#Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc9d70",
   "metadata": {},
   "source": [
    "# Test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d810955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "assistant: As a data governance consultant, I don't have personal preferences or feelings. However, I can provide insights into popular data tools that are widely used in the industry. Some of the most favored tools for data governance include:\n",
      "\n",
      "1. **Collibra**: Known for its comprehensive data governance capabilities, including data cataloging, data stewardship, and policy management.\n",
      "\n",
      "2. **Informatica**: Offers a robust suite of data governance tools, including data quality, data cataloging, and master data management.\n",
      "\n",
      "3. **Alation**: Focuses on data cataloging and collaboration, helping organizations improve data discovery and governance.\n",
      "\n",
      "4. **Talend**: Provides data integration and data quality tools that support data governance initiatives.\n",
      "\n",
      "5. **IBM InfoSphere**: Offers a range of data governance solutions, including data quality, master data management, and data integration.\n",
      "\n",
      "6. **Microsoft Purview**: A unified data governance service that helps manage and govern on-premises, multi-cloud, and software-as-a-service (SaaS) data.\n",
      "\n",
      "Each of these tools has its strengths and is chosen based on the specific needs and infrastructure of an organization.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a data governance consultant\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What's your favorite data tool ?\"),\n",
    "]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47252b4e-eb58-453c-9e7d-bab5286ee296",
   "metadata": {},
   "source": [
    "# Load storage contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e8019-e150-4a60-b59d-cac7a4aebcba",
   "metadata": {},
   "source": [
    "## Load vector storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42c55a04-2b21-4c05-96fb-f0f9ce26bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"vector\"),\n",
    "    vector_store=SimpleVectorStore.from_persist_dir(\n",
    "        persist_dir=\"vector\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"vector\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b951a-9776-46da-9309-142acfc3f1dd",
   "metadata": {},
   "source": [
    "## Load knowledge graph storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a086ef48-3be3-4a12-b158-4ed50aa2b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"knowledge_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28317dfb",
   "metadata": {},
   "source": [
    "## Load onto graph storage context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db73d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"onto_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d278b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x2c0bbc410>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x2c0868490>, vector_stores={'default': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={})), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x2bdaf54d0>, property_graph_store=None)\n"
     ]
    }
   ],
   "source": [
    "print(onto_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c3f5b-f0fa-4e10-85fd-9ff7642de428",
   "metadata": {},
   "source": [
    "# Load index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3e85a-8fca-4138-9ff9-fca4637a47e2",
   "metadata": {},
   "source": [
    "## Load vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68274006-61a7-42d7-9556-6ddae87d2b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "simple_index = load_index_from_storage(vector_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdab09-2c63-4e23-9ca3-79102db74cf0",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6c3e925-229f-4636-a7b7-73687a3aa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b32a3",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "887f57e4-8bc9-440b-a84c-0080cbd412e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb75ff03ed6e4294a77482682508b8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "simple_rag_retriever = simple_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = simple_query_engine.query(\n",
    "    \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f014fd60-81a4-4b7f-aef9-f545402e0fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, voici un plan structuré :\n",
       "\n",
       "1. **Compréhension des Données**\n",
       "   - Identifier les sources de données disponibles (historique des prêts, données démographiques, etc.).\n",
       "   - Définir l'objectif de la prédiction : comprendre les facteurs influençant le défaut de paiement.\n",
       "\n",
       "2. **Nettoyage des Données**\n",
       "   - Supprimer ou corriger les données inexactes ou les doublons.\n",
       "   - Remplir les données manquantes et uniformiser les formats (par exemple, dates).\n",
       "\n",
       "3. **Exploration des Données**\n",
       "   - Analyser les tendances et les relations entre les variables.\n",
       "   - Utiliser des visualisations pour identifier des patterns ou anomalies.\n",
       "\n",
       "4. **Préparation des Données**\n",
       "   - Transformer les données non structurées en un format exploitable.\n",
       "   - Sélectionner les caractéristiques pertinentes pour la modélisation.\n",
       "\n",
       "5. **Choix du Modèle**\n",
       "   - Sélectionner des modèles de machine learning adaptés (régression logistique, arbres de décision, etc.).\n",
       "   - Considérer l'utilisation d'outils spécialisés pour traiter les données complexes.\n",
       "\n",
       "6. **Entraînement et Validation du Modèle**\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "   - Entraîner le modèle sur l'ensemble d'entraînement et valider sa performance sur l'ensemble de test.\n",
       "\n",
       "7. **Évaluation du Modèle**\n",
       "   - Utiliser des métriques de performance (précision, rappel, F1-score) pour évaluer le modèle.\n",
       "   - Tester avec des parties prenantes pour recueillir des retours et apporter des modifications si nécessaires.\n",
       "\n",
       "8. **Interprétation et Communication des Résultats**\n",
       "   - Créer des visualisations claires pour communiquer les résultats aux parties prenantes.\n",
       "   - Assurer que les visualisations sont compréhensibles et utilisables par tous, y compris les personnes avec un handicap.\n",
       "\n",
       "9. **Mise en Production et Surveillance**\n",
       "   - Déployer le modèle dans un environnement de production.\n",
       "   - Surveiller la performance du modèle et effectuer des mises à jour régulières si nécessaire.\n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction de défaut de paiement en utilisant une approche méthodique et centrée sur les données.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242ad8d-20fb-4126-9380-4d51c7e3fa32",
   "metadata": {},
   "source": [
    "## Load graph index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75e3c260-c349-43f0-b54c-6dac7a12586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "graph_index = load_index_from_storage(graph_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81c1e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8424ed30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 49\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0388bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 74 nodes and 49 edges\n",
      "Nodes: ['Exactitude', 'Justes et cohérentes', 'Complétude', 'Complet', 'Nettoyage', 'Erreurs', 'Normalisation', 'Formats', 'Dataviz project', 'Relation entre inputs et visualisations de données', 'Bibliothèque', 'Description', '3v', 'Volume', 'Vélocité', 'Base de données relationnelles', 'Données structurées', 'Outils comme sql', 'Base de données non relationnelles', 'Données non structurées', 'Tirer', 'Données', 'Exploitables', 'Format prédéfini', 'Texte libre', 'Claire et standardisée', 'Passer', 'Interprétation des tendances', 'La data visualisation', 'Données brutes en graphiques', 'Information claire', 'Processus', 'Visualisation', 'Objectif', 'Message', 'Théophile', 'Outil informatique', 'Ordinateur', 'Quantité de données phénoménales', 'Phase', 'Choix des visualisations', 'Les utilisateurs', 'Les données', 'La visualisation', 'La source', 'Traitement', 'Les dataviz', 'Tester', 'Parties prenantes', 'Utilisateur', \"Niveaux d'informations\", 'Tout le monde', 'Personnes avec un handicap', 'Réflexion', \"Figure de l'utilisateur\", 'Llm', 'Quelque chose', 'Art', 'Sélectionner visualisation', 'Mettre en évidence messages', 'Métadonnées', 'Date de la prise de vue', 'Résolution', \"L'art de la dataviz\", 'Trucs en connaissances', 'Service communication', 'Série temporelle', 'Graphique en ligne', 'Comparaisons entre catégories', 'Diagramme à barre ou camembert', 'Examiner', 'Fournies', 'Identifier', 'Relations entre les données']\n",
      "Edges: [('Exactitude', 'Justes et cohérentes'), ('Complétude', 'Complet'), ('Nettoyage', 'Erreurs'), ('Normalisation', 'Formats'), ('Dataviz project', 'Relation entre inputs et visualisations de données'), ('Dataviz project', 'Bibliothèque'), ('Dataviz project', 'Description'), ('3v', 'Volume'), ('3v', 'Vélocité'), ('Base de données relationnelles', 'Données structurées'), ('Données structurées', 'Outils comme sql'), ('Base de données non relationnelles', 'Données non structurées'), ('Tirer', 'Données'), ('Données', 'Exploitables'), ('Données', 'Format prédéfini'), ('Données', 'Texte libre'), ('Données', 'Claire et standardisée'), ('Données', 'Processus'), ('Données', 'Phase'), ('Données', 'Les dataviz'), ('Données', 'Utilisateur'), ('Données', 'Service communication'), ('Passer', 'Interprétation des tendances'), ('La data visualisation', 'Données brutes en graphiques'), ('La data visualisation', 'Information claire'), ('Visualisation', 'Objectif'), ('Visualisation', 'Message'), ('Théophile', 'Outil informatique'), ('Ordinateur', 'Quantité de données phénoménales'), ('Phase', 'Choix des visualisations'), ('Les utilisateurs', 'Les données'), ('Les utilisateurs', 'La visualisation'), ('Les données', 'La source'), ('Les données', 'Traitement'), ('Tester', 'Parties prenantes'), ('Utilisateur', \"Niveaux d'informations\"), ('Utilisateur', 'Tout le monde'), ('Utilisateur', 'Personnes avec un handicap'), ('Réflexion', \"Figure de l'utilisateur\"), ('Llm', 'Quelque chose'), ('Art', 'Sélectionner visualisation'), ('Art', 'Mettre en évidence messages'), ('Métadonnées', 'Date de la prise de vue'), ('Métadonnées', 'Résolution'), (\"L'art de la dataviz\", 'Trucs en connaissances'), ('Série temporelle', 'Graphique en ligne'), ('Comparaisons entre catégories', 'Diagramme à barre ou camembert'), ('Examiner', 'Fournies'), ('Identifier', 'Relations entre les données')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d6f30",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "330e38ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e323b",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0dd0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65646625893413595e5ebc1eaf50613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a5d8f92d-8c56-4951-9949-000a7f8e5928: Ajout d'éléments dynamiques pour permettre aux [[utilisateur]]s d'explorer le...\n",
      "> Querying with idx: a5d8f92d-8c56-4951-9949-000a7f8e5928: Ajout d'éléments dynamiques pour permettre aux [[utilisateur]]s d'explorer le...\n",
      "> Querying with idx: a5d8f92d-8c56-4951-9949-000a7f8e5928: Ajout d'éléments dynamiques pour permettre aux [[utilisateur]]s d'explorer le...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6b6f94f9-b344-436a-941e-a0dfe3ea3d0b: Réflexion à mener sur la figure de l'utilisateur dans le parcours par rapport...\n",
      "> Querying with idx: 6b6f94f9-b344-436a-941e-a0dfe3ea3d0b: Réflexion à mener sur la figure de l'utilisateur dans le parcours par rapport...\n",
      "> Querying with idx: 6b6f94f9-b344-436a-941e-a0dfe3ea3d0b: Réflexion à mener sur la figure de l'utilisateur dans le parcours par rapport...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2169fdc7-cfa9-4e78-881b-f9efe2b54619: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 2169fdc7-cfa9-4e78-881b-f9efe2b54619: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 2169fdc7-cfa9-4e78-881b-f9efe2b54619: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 43e80573-07f2-46ab-bb7b-bfa1b1243ac4: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 43e80573-07f2-46ab-bb7b-bfa1b1243ac4: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 43e80573-07f2-46ab-bb7b-bfa1b1243ac4: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7d22f37d-2213-4cd1-9683-85c479223b09: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 7d22f37d-2213-4cd1-9683-85c479223b09: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 7d22f37d-2213-4cd1-9683-85c479223b09: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: eca8d804-0a98-4a2f-adcd-adb4e3c1bc29: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: eca8d804-0a98-4a2f-adcd-adb4e3c1bc29: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: eca8d804-0a98-4a2f-adcd-adb4e3c1bc29: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0a85dc79-9b62-408f-a128-021a7abc1666: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 0a85dc79-9b62-408f-a128-021a7abc1666: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 0a85dc79-9b62-408f-a128-021a7abc1666: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 19f099cd-93ae-49aa-8f98-5972b2df1524: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 19f099cd-93ae-49aa-8f98-5972b2df1524: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 19f099cd-93ae-49aa-8f98-5972b2df1524: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: c98c10b5-a9fa-4ebb-8105-f0bc30fdac0f: Tirer des conclusions ou des insights à partir des [[données]]. \n",
      "Ou comment p...\n",
      "> Querying with idx: c98c10b5-a9fa-4ebb-8105-f0bc30fdac0f: Tirer des conclusions ou des insights à partir des [[données]]. \n",
      "Ou comment p...\n",
      "> Querying with idx: c98c10b5-a9fa-4ebb-8105-f0bc30fdac0f: Tirer des conclusions ou des insights à partir des [[données]]. \n",
      "Ou comment p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: ae932859-5db4-4cc6-b5a0-260b88288383: Phase d'analyse des [[données|données]] pour comprendre leur structure, détec...\n",
      "> Querying with idx: ae932859-5db4-4cc6-b5a0-260b88288383: Phase d'analyse des [[données|données]] pour comprendre leur structure, détec...\n",
      "> Querying with idx: ae932859-5db4-4cc6-b5a0-260b88288383: Phase d'analyse des [[données|données]] pour comprendre leur structure, détec...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "graph_rag_retriever = graph_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(\n",
    "    \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1031a44-f06e-400f-beaa-2065beeee9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, il est essentiel de suivre un plan structuré qui inclut plusieurs étapes clés. Voici un plan détaillé :\n",
       "\n",
       "1. **Collecte et Préparation des Données :**\n",
       "   - Rassembler les données pertinentes sur les clients, y compris les historiques de crédit, les revenus, les dettes, et d'autres facteurs financiers.\n",
       "   - S'assurer que les données sont organisées de manière claire et standardisée, souvent dans un tableau avec des lignes et des colonnes.\n",
       "   - Nettoyer les données pour éliminer les anomalies et les valeurs manquantes.\n",
       "\n",
       "2. **Exploration des Données :**\n",
       "   - Analyser la structure des données pour comprendre les relations entre les différentes variables.\n",
       "   - Utiliser des outils comme SQL pour interroger les données structurées et obtenir des insights préliminaires.\n",
       "\n",
       "3. **Analyse des Données :**\n",
       "   - Identifier les tendances et les corrélations qui pourraient indiquer un risque de défaut.\n",
       "   - Utiliser des visualisations appropriées pour représenter les données, comme des diagrammes à barres pour les comparaisons entre catégories ou des courbes pour les tendances.\n",
       "\n",
       "4. **Sélection des Caractéristiques :**\n",
       "   - Choisir les variables les plus pertinentes qui influencent le risque de défaut, en se basant sur l'analyse exploratoire.\n",
       "\n",
       "5. **Modélisation Prédictive :**\n",
       "   - Utiliser des algorithmes de machine learning pour construire un modèle prédictif. Les modèles couramment utilisés incluent la régression logistique, les arbres de décision, ou les forêts aléatoires.\n",
       "   - Diviser les données en ensembles d'entraînement et de test pour évaluer la performance du modèle.\n",
       "\n",
       "6. **Évaluation du Modèle :**\n",
       "   - Mesurer la précision du modèle en utilisant des métriques telles que l'accuracy, le rappel, et la précision.\n",
       "   - Ajuster le modèle en fonction des résultats pour améliorer sa performance.\n",
       "\n",
       "7. **Interprétation et Communication des Résultats :**\n",
       "   - Interpréter les résultats du modèle pour comprendre les facteurs clés qui contribuent au risque de défaut.\n",
       "   - Communiquer les résultats de manière compréhensible et utilisable par tous les utilisateurs, y compris ceux avec un handicap.\n",
       "\n",
       "8. **Mise en Œuvre et Surveillance :**\n",
       "   - Déployer le modèle dans un environnement de production pour prédire les défauts en temps réel.\n",
       "   - Surveiller la performance du modèle et le mettre à jour régulièrement pour s'adapter aux nouvelles données et aux changements de comportement des clients.\n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction du défaut de paiement de manière méthodique et efficace.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e7541",
   "metadata": {},
   "source": [
    "## Load onto index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb203e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(persist_dir=\"onto_graph\")\n",
    "# Load the PropertyGraphIndex from the storage context\n",
    "\n",
    "onto_index = load_index_from_storage(onto_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a182d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_index.property_graph_store.save_networkx_graph(\n",
    "    name=\"OntoGraph.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4dcae",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bee17732",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95920ba",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c400086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4ad0ac55fd440d9dbd0cc7ba93a083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "onto_rag_retriever = onto_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(\n",
    "    \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "123366e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, voici un plan structuré :\n",
       "\n",
       "1. **Collecte et Préparation des Données**\n",
       "   - **Collecte des Données** : Rassembler les données historiques des clients, y compris les informations démographiques, les antécédents de crédit, les transactions bancaires, etc.\n",
       "   - **Nettoyage des Données** : Supprimer ou corriger les données inexactes, éliminer les doublons, et remplir les données manquantes.\n",
       "   - **Normalisation et Transformation** : Uniformiser les formats de données et transformer les données pour les adapter aux outils d'analyse.\n",
       "\n",
       "2. **Exploration et Analyse des Données**\n",
       "   - **Analyse Exploratoire** : Identifier les tendances et les relations dans les données à l'aide de visualisations.\n",
       "   - **Sélection des Caractéristiques** : Déterminer les variables les plus pertinentes qui influencent le défaut de paiement.\n",
       "\n",
       "3. **Modélisation Prédictive**\n",
       "   - **Choix du Modèle** : Sélectionner un modèle de machine learning approprié (par exemple, régression logistique, arbres de décision, forêts aléatoires).\n",
       "   - **Entraînement du Modèle** : Utiliser un ensemble de données d'entraînement pour ajuster le modèle.\n",
       "   - **Validation du Modèle** : Évaluer la performance du modèle avec un ensemble de données de validation.\n",
       "\n",
       "4. **Évaluation et Optimisation**\n",
       "   - **Évaluation des Performances** : Utiliser des métriques telles que l'accuracy, le rappel, et la précision pour évaluer le modèle.\n",
       "   - **Optimisation** : Ajuster les hyperparamètres et améliorer le modèle en fonction des résultats d'évaluation.\n",
       "\n",
       "5. **Déploiement et Surveillance**\n",
       "   - **Déploiement** : Intégrer le modèle dans le système bancaire pour des prédictions en temps réel.\n",
       "   - **Surveillance Continue** : Suivre la performance du modèle et mettre à jour les données et le modèle régulièrement pour maintenir l'exactitude des prédictions.\n",
       "\n",
       "6. **Interprétation et Communication**\n",
       "   - **Interprétation des Résultats** : Analyser les résultats pour comprendre les facteurs clés de défaut.\n",
       "   - **Communication** : Présenter les résultats aux parties prenantes à l'aide de visualisations claires et concises.\n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction du défaut de paiement en utilisant des méthodes analytiques et des outils de dataviz pour une meilleure compréhension et application des résultats.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b65be-955e-44db-942e-27e235384f19",
   "metadata": {},
   "source": [
    "# Visualize knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55ef03a2-2e7e-443d-865f-b6d991d16416",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9d58e14-0017-494f-98ec-ad8b30bf8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 49\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a113918c-f195-4c8c-b0f3-c85d7a6c5d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 74 nodes and 49 edges\n",
      "Nodes: ['Exactitude', 'Justes et cohérentes', 'Complétude', 'Complet', 'Nettoyage', 'Erreurs', 'Normalisation', 'Formats', 'Dataviz project', 'Relation entre inputs et visualisations de données', 'Bibliothèque', 'Description', '3v', 'Volume', 'Vélocité', 'Base de données relationnelles', 'Données structurées', 'Outils comme sql', 'Base de données non relationnelles', 'Données non structurées', 'Tirer', 'Données', 'Exploitables', 'Format prédéfini', 'Texte libre', 'Claire et standardisée', 'Passer', 'Interprétation des tendances', 'La data visualisation', 'Données brutes en graphiques', 'Information claire', 'Processus', 'Visualisation', 'Objectif', 'Message', 'Théophile', 'Outil informatique', 'Ordinateur', 'Quantité de données phénoménales', 'Phase', 'Choix des visualisations', 'Les utilisateurs', 'Les données', 'La visualisation', 'La source', 'Traitement', 'Les dataviz', 'Tester', 'Parties prenantes', 'Utilisateur', \"Niveaux d'informations\", 'Tout le monde', 'Personnes avec un handicap', 'Réflexion', \"Figure de l'utilisateur\", 'Llm', 'Quelque chose', 'Art', 'Sélectionner visualisation', 'Mettre en évidence messages', 'Métadonnées', 'Date de la prise de vue', 'Résolution', \"L'art de la dataviz\", 'Trucs en connaissances', 'Service communication', 'Série temporelle', 'Graphique en ligne', 'Comparaisons entre catégories', 'Diagramme à barre ou camembert', 'Examiner', 'Fournies', 'Identifier', 'Relations entre les données']\n",
      "Edges: [('Exactitude', 'Justes et cohérentes'), ('Complétude', 'Complet'), ('Nettoyage', 'Erreurs'), ('Normalisation', 'Formats'), ('Dataviz project', 'Relation entre inputs et visualisations de données'), ('Dataviz project', 'Bibliothèque'), ('Dataviz project', 'Description'), ('3v', 'Volume'), ('3v', 'Vélocité'), ('Base de données relationnelles', 'Données structurées'), ('Données structurées', 'Outils comme sql'), ('Base de données non relationnelles', 'Données non structurées'), ('Tirer', 'Données'), ('Données', 'Exploitables'), ('Données', 'Format prédéfini'), ('Données', 'Texte libre'), ('Données', 'Claire et standardisée'), ('Données', 'Processus'), ('Données', 'Phase'), ('Données', 'Les dataviz'), ('Données', 'Utilisateur'), ('Données', 'Service communication'), ('Passer', 'Interprétation des tendances'), ('La data visualisation', 'Données brutes en graphiques'), ('La data visualisation', 'Information claire'), ('Visualisation', 'Objectif'), ('Visualisation', 'Message'), ('Théophile', 'Outil informatique'), ('Ordinateur', 'Quantité de données phénoménales'), ('Phase', 'Choix des visualisations'), ('Les utilisateurs', 'Les données'), ('Les utilisateurs', 'La visualisation'), ('Les données', 'La source'), ('Les données', 'Traitement'), ('Tester', 'Parties prenantes'), ('Utilisateur', \"Niveaux d'informations\"), ('Utilisateur', 'Tout le monde'), ('Utilisateur', 'Personnes avec un handicap'), ('Réflexion', \"Figure de l'utilisateur\"), ('Llm', 'Quelque chose'), ('Art', 'Sélectionner visualisation'), ('Art', 'Mettre en évidence messages'), ('Métadonnées', 'Date de la prise de vue'), ('Métadonnées', 'Résolution'), (\"L'art de la dataviz\", 'Trucs en connaissances'), ('Série temporelle', 'Graphique en ligne'), ('Comparaisons entre catégories', 'Diagramme à barre ou camembert'), ('Examiner', 'Fournies'), ('Identifier', 'Relations entre les données')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab94fc0-2080-4869-94a0-b013dc0fbd9d",
   "metadata": {},
   "source": [
    "# (Simple) Query the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c93bdbb-aaa4-4658-aecf-1cd7b5038ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b089a219ab44ae81244b8b9fd4e28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\"\n",
    "query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e2a871b4-70c8-45ed-a8b9-b2aaa8d15a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, voici un plan structuré :\n",
       "\n",
       "1. **Compréhension des Données**\n",
       "   - Identifier les sources de données disponibles (historique des prêts, données démographiques, etc.).\n",
       "   - Définir l'objectif de la prédiction : comprendre les facteurs influençant le défaut de paiement.\n",
       "\n",
       "2. **Nettoyage des Données**\n",
       "   - Supprimer ou corriger les données inexactes ou les doublons.\n",
       "   - Remplir les données manquantes et uniformiser les formats (par exemple, dates).\n",
       "\n",
       "3. **Exploration des Données**\n",
       "   - Analyser les données pour identifier des tendances ou des corrélations.\n",
       "   - Utiliser des visualisations pour mieux comprendre les relations entre les variables.\n",
       "\n",
       "4. **Préparation des Données**\n",
       "   - Transformer les données non structurées en un format exploitable.\n",
       "   - Sélectionner les caractéristiques pertinentes pour la modélisation.\n",
       "\n",
       "5. **Choix du Modèle**\n",
       "   - Sélectionner un modèle de machine learning approprié (par exemple, régression logistique, arbres de décision).\n",
       "   - Justifier le choix du modèle en fonction des données et de l'objectif.\n",
       "\n",
       "6. **Entraînement du Modèle**\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "   - Entraîner le modèle sur l'ensemble d'entraînement.\n",
       "\n",
       "7. **Évaluation du Modèle**\n",
       "   - Tester le modèle sur l'ensemble de test.\n",
       "   - Utiliser des métriques d'évaluation (précision, rappel, F1-score) pour mesurer la performance.\n",
       "\n",
       "8. **Optimisation du Modèle**\n",
       "   - Ajuster les hyperparamètres pour améliorer la performance.\n",
       "   - Réévaluer le modèle après chaque ajustement.\n",
       "\n",
       "9. **Interprétation des Résultats**\n",
       "   - Analyser les résultats pour comprendre les facteurs clés du défaut de paiement.\n",
       "   - Communiquer les résultats de manière claire et compréhensible.\n",
       "\n",
       "10. **Mise en Production**\n",
       "    - Déployer le modèle dans un environnement de production.\n",
       "    - Mettre en place un système de surveillance pour suivre la performance du modèle.\n",
       "\n",
       "11. **Amélioration Continue**\n",
       "    - Recueillir des retours et ajuster le modèle en fonction des nouvelles données.\n",
       "    - Réévaluer régulièrement le modèle pour s'assurer de sa pertinence et de son efficacité.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099031c-b137-468f-b20c-9c6fab1c4eb1",
   "metadata": {},
   "source": [
    "# (Simple) Query the knowledge graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8948dd2b-acd4-4621-a2d1-b45034a21007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c4a07b701d469c977a5487c1e6a537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a5d8f92d-8c56-4951-9949-000a7f8e5928: Ajout d'éléments dynamiques pour permettre aux [[utilisateur]]s d'explorer le...\n",
      "> Querying with idx: a5d8f92d-8c56-4951-9949-000a7f8e5928: Ajout d'éléments dynamiques pour permettre aux [[utilisateur]]s d'explorer le...\n",
      "> Querying with idx: a5d8f92d-8c56-4951-9949-000a7f8e5928: Ajout d'éléments dynamiques pour permettre aux [[utilisateur]]s d'explorer le...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 6b6f94f9-b344-436a-941e-a0dfe3ea3d0b: Réflexion à mener sur la figure de l'utilisateur dans le parcours par rapport...\n",
      "> Querying with idx: 6b6f94f9-b344-436a-941e-a0dfe3ea3d0b: Réflexion à mener sur la figure de l'utilisateur dans le parcours par rapport...\n",
      "> Querying with idx: 6b6f94f9-b344-436a-941e-a0dfe3ea3d0b: Réflexion à mener sur la figure de l'utilisateur dans le parcours par rapport...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2169fdc7-cfa9-4e78-881b-f9efe2b54619: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 2169fdc7-cfa9-4e78-881b-f9efe2b54619: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 2169fdc7-cfa9-4e78-881b-f9efe2b54619: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 43e80573-07f2-46ab-bb7b-bfa1b1243ac4: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 43e80573-07f2-46ab-bb7b-bfa1b1243ac4: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 43e80573-07f2-46ab-bb7b-bfa1b1243ac4: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7d22f37d-2213-4cd1-9683-85c479223b09: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 7d22f37d-2213-4cd1-9683-85c479223b09: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 7d22f37d-2213-4cd1-9683-85c479223b09: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: eca8d804-0a98-4a2f-adcd-adb4e3c1bc29: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: eca8d804-0a98-4a2f-adcd-adb4e3c1bc29: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: eca8d804-0a98-4a2f-adcd-adb4e3c1bc29: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0a85dc79-9b62-408f-a128-021a7abc1666: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 0a85dc79-9b62-408f-a128-021a7abc1666: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 0a85dc79-9b62-408f-a128-021a7abc1666: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 19f099cd-93ae-49aa-8f98-5972b2df1524: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 19f099cd-93ae-49aa-8f98-5972b2df1524: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "> Querying with idx: 19f099cd-93ae-49aa-8f98-5972b2df1524: Système organisé pour stocker, gérer et récupérer des données \n",
      "Essentielles p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: c98c10b5-a9fa-4ebb-8105-f0bc30fdac0f: Tirer des conclusions ou des insights à partir des [[données]]. \n",
      "Ou comment p...\n",
      "> Querying with idx: c98c10b5-a9fa-4ebb-8105-f0bc30fdac0f: Tirer des conclusions ou des insights à partir des [[données]]. \n",
      "Ou comment p...\n",
      "> Querying with idx: c98c10b5-a9fa-4ebb-8105-f0bc30fdac0f: Tirer des conclusions ou des insights à partir des [[données]]. \n",
      "Ou comment p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: ae932859-5db4-4cc6-b5a0-260b88288383: Phase d'analyse des [[données|données]] pour comprendre leur structure, détec...\n",
      "> Querying with idx: ae932859-5db4-4cc6-b5a0-260b88288383: Phase d'analyse des [[données|données]] pour comprendre leur structure, détec...\n",
      "> Querying with idx: ae932859-5db4-4cc6-b5a0-260b88288383: Phase d'analyse des [[données|données]] pour comprendre leur structure, détec...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan\"\n",
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff5382fd-1fc8-4faf-9356-c9bb3e478db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, il est essentiel de suivre un plan structuré qui inclut plusieurs étapes clés. Voici un plan détaillé :\n",
       "\n",
       "1. **Collecte et Préparation des Données :**\n",
       "   - Rassembler les données pertinentes sur les clients, y compris les historiques de crédit, les revenus, les dettes, et d'autres facteurs financiers.\n",
       "   - Nettoyer les données pour éliminer les valeurs manquantes ou aberrantes.\n",
       "   - Organiser les données de manière claire et standardisée, souvent dans un tableau avec des lignes et des colonnes.\n",
       "\n",
       "2. **Exploration des Données :**\n",
       "   - Analyser la structure des données pour comprendre les relations entre les différentes variables.\n",
       "   - Utiliser des outils de visualisation pour identifier les tendances et les anomalies.\n",
       "\n",
       "3. **Sélection des Caractéristiques :**\n",
       "   - Identifier les caractéristiques les plus pertinentes qui pourraient influencer le défaut de paiement.\n",
       "   - Utiliser des techniques de réduction de dimensionnalité si nécessaire pour simplifier le modèle.\n",
       "\n",
       "4. **Choix du Modèle :**\n",
       "   - Sélectionner un modèle de machine learning approprié, tel que la régression logistique, les arbres de décision, ou les forêts aléatoires.\n",
       "   - Considérer l'utilisation de modèles plus avancés comme les réseaux de neurones si les données sont suffisamment volumineuses et complexes.\n",
       "\n",
       "5. **Entraînement du Modèle :**\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "   - Entraîner le modèle sur l'ensemble d'entraînement en ajustant les paramètres pour optimiser la performance.\n",
       "\n",
       "6. **Évaluation du Modèle :**\n",
       "   - Tester le modèle sur l'ensemble de test pour évaluer sa précision et sa capacité à prédire les défauts de paiement.\n",
       "   - Utiliser des métriques telles que l'accuracy, le rappel, et la précision pour évaluer la performance.\n",
       "\n",
       "7. **Optimisation et Validation :**\n",
       "   - Affiner le modèle en ajustant les hyperparamètres et en utilisant des techniques de validation croisée.\n",
       "   - S'assurer que le modèle n'est pas surajusté et qu'il généralise bien aux nouvelles données.\n",
       "\n",
       "8. **Déploiement et Surveillance :**\n",
       "   - Déployer le modèle dans un environnement de production pour prédire les défauts de paiement en temps réel.\n",
       "   - Mettre en place un système de surveillance pour suivre la performance du modèle et effectuer des mises à jour si nécessaire.\n",
       "\n",
       "En suivant ces étapes, vous pouvez développer un modèle robuste pour prédire les défauts de paiement sur les prêts bancaires.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef119d0",
   "metadata": {},
   "source": [
    "# (Simple) Query the onto graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8db6420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8973d30a6364b28a1d1c130123e5ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\"\n",
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=2,\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "adcd4265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, voici un plan structuré :\n",
       "\n",
       "1. **Collecte des données :**\n",
       "   - Rassembler des données historiques sur les clients, y compris les informations démographiques, les antécédents de crédit, les revenus, les dettes existantes, etc.\n",
       "   - Inclure des données sur les prêts précédents et leur statut (remboursé ou en défaut).\n",
       "\n",
       "2. **Préparation des données :**\n",
       "   - Nettoyer les données pour éliminer les valeurs manquantes ou aberrantes.\n",
       "   - Normaliser ou standardiser les variables numériques pour assurer une échelle uniforme.\n",
       "   - Encoder les variables catégorielles en valeurs numériques.\n",
       "\n",
       "3. **Exploration des données :**\n",
       "   - Utiliser des techniques de visualisation de données pour identifier les tendances et les relations entre les variables.\n",
       "   - Analyser les inférences pour comprendre les facteurs qui influencent le défaut de paiement.\n",
       "\n",
       "4. **Sélection des caractéristiques :**\n",
       "   - Identifier les caractéristiques les plus pertinentes qui influencent le défaut de paiement à l'aide de techniques comme l'analyse de corrélation ou l'importance des caractéristiques.\n",
       "\n",
       "5. **Modélisation :**\n",
       "   - Choisir un modèle de machine learning approprié, tel que la régression logistique, les arbres de décision, ou les forêts aléatoires.\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "\n",
       "6. **Entraînement du modèle :**\n",
       "   - Entraîner le modèle sur l'ensemble d'entraînement.\n",
       "   - Ajuster les hyperparamètres pour optimiser les performances du modèle.\n",
       "\n",
       "7. **Évaluation du modèle :**\n",
       "   - Évaluer le modèle sur l'ensemble de test en utilisant des métriques telles que l'exactitude, la précision, le rappel, et le score F1.\n",
       "   - Analyser les erreurs pour comprendre les limitations du modèle.\n",
       "\n",
       "8. **Interprétation et déploiement :**\n",
       "   - Interpréter les résultats pour fournir des insights exploitables aux décideurs.\n",
       "   - Déployer le modèle dans un environnement de production pour prédire les défauts de paiement en temps réel.\n",
       "\n",
       "9. **Surveillance et mise à jour :**\n",
       "   - Surveiller les performances du modèle au fil du temps.\n",
       "   - Mettre à jour le modèle avec de nouvelles données pour maintenir sa précision et sa pertinence. \n",
       "\n",
       "Ce plan permet de structurer l'approche pour prédire les défauts de paiement en utilisant des données et des techniques analytiques avancées.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582274ba",
   "metadata": {},
   "source": [
    "## (Node retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16db2a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87be037349a42398c6721c9243a2b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "jeu de données -> CONFRONTED_WITH -> que faire\n",
      "\n",
      "Réflexion à mener sur la figure de l'utilisateur dans le parcours par rapport aux données ? \n",
      "\n",
      "Retrouver le schéma dataviz : que faire si je me retrouve face à un jeu de données \n",
      "Est ce que c'est quelque chose que le LLM peut lire ?\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "pertinence -> EXTENDS_TO -> besoins du client\n",
      "\n",
      "Quels critères pour dire que des données sont de qualité ?\n",
      "- Exactitude : les données sont justes et cohérentes\n",
      "- Complétude : le jeu de données est complet \n",
      "- Pertinence : les données que l'on a sont elles pertinentes pour répondre à nos besoins (et par extension ceux du client ?)\n",
      "\n",
      "Des données de bonnes qualités sont essentielles pour avoir des donnes fiables\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "Théophile -> BELIEVES -> donnée liée à outil informatique\n",
      "\n",
      "> Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à la gueule et on me dit \"allez, fais moi une synthèse graphique\" et je suis paumé\n",
      "\n",
      "\n",
      "\n",
      "Que faire quand on se retrouve face à une montagne de [[données]]\n",
      "Quels sont les [[outils]] à disposition ? \n",
      "Quelles sont les bonnes pratiques pour réceptionner, gérer et exploiter des données ? \n",
      "\n",
      "\n",
      "Quelle est la part d'adaptation que l'on peut offrir quand on se retrouve face à quelque chose d'aussi rigoureux que la manipulation de données ?\n",
      "\n",
      "Pour moi (théophile) : la question de la donnée est intrinsèquement liée à la question de l'outil informatique puisque c'est comme ça qu'on la manipule aujourd'hui. Mais il y a aussi quelque chose de vertigineux dans le fait que l'outil avec lequel on manipule nos données (un ordinateur) manipule lui même une quantité de données phénoménales.\n",
      "\n",
      "La donnée des uns sera-t-elle la donnée des autres ? \n",
      "Comment assurer une transmission de la donnée ? \n",
      "Est-ce tout le point de la dataviz ? \n",
      "\n",
      "Dans la question de la dataviz et de son but il y a la question de l'interaction entre l'homme et la donnée\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "service communication -> UNDERSTANDS -> ce qui a mieux ou moins bien marché\n",
      "\n",
      "Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas de trucs qu'on sait pas trop comment définir en des connaissances et des idées et leur donner une application dans la vie courante.\n",
      "\n",
      "**Exemple :** Le service communication d'une entreprise analyse les données relatives à l'envoi d'une newsletter pour comprendre ce qui a mieux ou moins bien marché. Ils utilisent des outils qui mettent en forment les données et en produisent des évaluations, parfois même des interprétations.\n",
      "\n",
      "Pour comprendre les données, on cherche à analyser les [[Inférence]]s et trouver des relation dans notre tas d'informations.\n"
     ]
    }
   ],
   "source": [
    "retriever = onto_index.as_retriever(\n",
    "    include_text=True,  # include source text, default True\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire ?\")\n",
    "\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a895520-d196-476f-b569-69a67484c120",
   "metadata": {},
   "source": [
    "# Have a real chat with your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3764d-a084-4f36-9d8c-3613aa9fd835",
   "metadata": {},
   "source": [
    "## Set up the engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e55a2-a9a9-4c4e-89a4-c4dfba55ebe4",
   "metadata": {},
   "source": [
    "### Vector engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1581c90c-cf5a-40d3-81b0-086238068f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "vector_chat_engine = simple_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \" \"\n",
    "        \" \"\n",
    "        \".\"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a1c22-111b-4793-8a3d-bd3eae7e3ec7",
   "metadata": {},
   "source": [
    "### Graph engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "98b73cc2-0588-4b96-9aa2-1dfaf4cadb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897ec22",
   "metadata": {},
   "source": [
    "### Onto engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54d04e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onto_chat_engine = onto_index.query_engine(\n",
    "#    chat_mode=\"condense_plus_context\",\n",
    "#    llm=llm\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e0a08-f6ff-4ee6-a165-9b9fd90621fa",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "12804e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chat_engine.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "709a37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \" \"\n",
    "        \" \"\n",
    "        \" \"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "da3e3ebf-18dc-4bdc-87dc-58d0227e9c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question:  \n",
      "Condensed question:  \n",
      "Condensed question:  \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bbea2bb3d94ee5b414c9e04c4c2469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 02d20359-7216-420e-bdc7-6fe57a70b452: Art de raconter une histoire avec des [[données]] \n",
      "Implique de : \n",
      "- Sélection...\n",
      "> Querying with idx: 02d20359-7216-420e-bdc7-6fe57a70b452: Art de raconter une histoire avec des [[données]] \n",
      "Implique de : \n",
      "- Sélection...\n",
      "> Querying with idx: 02d20359-7216-420e-bdc7-6fe57a70b452: Art de raconter une histoire avec des [[données]] \n",
      "Implique de : \n",
      "- Sélection...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: a5d8f92d-8c56-4951-9949-000a7f8e5928: Ajout d'éléments dynamiques pour permettre aux [[utilisateur]]s d'explorer le...\n",
      "> Querying with idx: a5d8f92d-8c56-4951-9949-000a7f8e5928: Ajout d'éléments dynamiques pour permettre aux [[utilisateur]]s d'explorer le...\n",
      "> Querying with idx: a5d8f92d-8c56-4951-9949-000a7f8e5928: Ajout d'éléments dynamiques pour permettre aux [[utilisateur]]s d'explorer le...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 43e80573-07f2-46ab-bb7b-bfa1b1243ac4: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 43e80573-07f2-46ab-bb7b-bfa1b1243ac4: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "> Querying with idx: 43e80573-07f2-46ab-bb7b-bfa1b1243ac4: Créer des visualisations compréhensibles et utilisables par tout le monde ([[...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: c98c10b5-a9fa-4ebb-8105-f0bc30fdac0f: Tirer des conclusions ou des insights à partir des [[données]]. \n",
      "Ou comment p...\n",
      "> Querying with idx: c98c10b5-a9fa-4ebb-8105-f0bc30fdac0f: Tirer des conclusions ou des insights à partir des [[données]]. \n",
      "Ou comment p...\n",
      "> Querying with idx: c98c10b5-a9fa-4ebb-8105-f0bc30fdac0f: Tirer des conclusions ou des insights à partir des [[données]]. \n",
      "Ou comment p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: ae932859-5db4-4cc6-b5a0-260b88288383: Phase d'analyse des [[données|données]] pour comprendre leur structure, détec...\n",
      "> Querying with idx: ae932859-5db4-4cc6-b5a0-260b88288383: Phase d'analyse des [[données|données]] pour comprendre leur structure, détec...\n",
      "> Querying with idx: ae932859-5db4-4cc6-b5a0-260b88288383: Phase d'analyse des [[données|données]] pour comprendre leur structure, détec...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2169fdc7-cfa9-4e78-881b-f9efe2b54619: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 2169fdc7-cfa9-4e78-881b-f9efe2b54619: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 2169fdc7-cfa9-4e78-881b-f9efe2b54619: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 5c63b8d9-7482-4848-8ffd-44474ad02aca: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 5c63b8d9-7482-4848-8ffd-44474ad02aca: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 5c63b8d9-7482-4848-8ffd-44474ad02aca: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2f041ade-a741-40c3-b55e-0159979a8c09: Les [[dataviz]] produitent reflètent-elles fidèlement les données d'[[Input]]...\n",
      "> Querying with idx: 2f041ade-a741-40c3-b55e-0159979a8c09: Les [[dataviz]] produitent reflètent-elles fidèlement les données d'[[Input]]...\n",
      "> Querying with idx: 2f041ade-a741-40c3-b55e-0159979a8c09: Les [[dataviz]] produitent reflètent-elles fidèlement les données d'[[Input]]...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 950c1d9b-b969-4f2b-bf34-5fa97319f716: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 950c1d9b-b969-4f2b-bf34-5fa97319f716: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 950c1d9b-b969-4f2b-bf34-5fa97319f716: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0a85dc79-9b62-408f-a128-021a7abc1666: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 0a85dc79-9b62-408f-a128-021a7abc1666: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 0a85dc79-9b62-408f-a128-021a7abc1666: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\" \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "91ebf21f-1990-4a4d-9c9a-868872f03042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Hello! How can I assist you today?"
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a056a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6660a81e-ad67-4d44-a86d-0ad7b77f626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_modele = \"\"\" \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9c0e462e-d3ee-463a-8d49-f09dc2396b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: Pouvez-vous imiter le style d'écriture de la {section_modele} ?\n",
      "Condensed question: Pouvez-vous imiter le style d'écriture de la {section_modele} ?\n",
      "Condensed question: Pouvez-vous imiter le style d'écriture de la {section_modele} ?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46876b80bd864e5cb3a03707e6425b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 5a8ae5a3-e79f-4ca5-b9ed-4554c57f7e2f: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: 5a8ae5a3-e79f-4ca5-b9ed-4554c57f7e2f: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: 5a8ae5a3-e79f-4ca5-b9ed-4554c57f7e2f: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 02d20359-7216-420e-bdc7-6fe57a70b452: Art de raconter une histoire avec des [[données]] \n",
      "Implique de : \n",
      "- Sélection...\n",
      "> Querying with idx: 02d20359-7216-420e-bdc7-6fe57a70b452: Art de raconter une histoire avec des [[données]] \n",
      "Implique de : \n",
      "- Sélection...\n",
      "> Querying with idx: 02d20359-7216-420e-bdc7-6fe57a70b452: Art de raconter une histoire avec des [[données]] \n",
      "Implique de : \n",
      "- Sélection...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 65ac65e0-e9e5-4d2e-a5a2-30e5b1e29a90: ---\n",
      "url: https://datavizproject.com/\n",
      "---\n",
      "Dataviz project est une bibliothèque...\n",
      "> Querying with idx: 65ac65e0-e9e5-4d2e-a5a2-30e5b1e29a90: ---\n",
      "url: https://datavizproject.com/\n",
      "---\n",
      "Dataviz project est une bibliothèque...\n",
      "> Querying with idx: 65ac65e0-e9e5-4d2e-a5a2-30e5b1e29a90: ---\n",
      "url: https://datavizproject.com/\n",
      "---\n",
      "Dataviz project est une bibliothèque...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"Imite le style d'écriture de la {section_modele}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c86075ee-12c8-4b97-8b51-0c717fc4b1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Je suis désolé, mais il semble qu'il y ait eu une petite confusion dans votre demande. Pourriez-vous préciser quel style d'écriture ou quel modèle vous aimeriez que j'imite ? Cela m'aiderait à mieux répondre à votre demande. Merci !"
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ffb78d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74a302-bb28-4bf8-9103-1f62750a5fc0",
   "metadata": {},
   "source": [
    "## Sum-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d81f7480-9d62-4952-948e-19e089d9da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = memory.get_all()\n",
    "\n",
    "# Assuming chat_history is available and contains your messages\n",
    "assistant_messages = [\n",
    "    message.content \n",
    "    for message in chat_history \n",
    "    if message.role == MessageRole.ASSISTANT  # Compare with the enum directly\n",
    "]\n",
    "\n",
    "\n",
    "output_filename = r\"/Users/arthursarazin/Documents/coreandgraphs/graphandvisualize/output.md\"\n",
    "# Write to a Markdown file\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    for msg in assistant_messages:\n",
    "        f.write(msg + \"\\n\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
