{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "614fc4e2-0e04-49b0-bf7c-05efee48933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.obsidian import ObsidianReader\n",
    "from llama_index.core.memory.chat_memory_buffer import MessageRole\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex, VectorStoreIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import Document, PropertyGraphIndex\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "import logging\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    SimpleLLMPathExtractor,\n",
    "    SchemaLLMPathExtractor,\n",
    "    DynamicLLMPathExtractor,\n",
    ")\n",
    "import yaml\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5e9f925-0bd9-406c-a41d-8be268260b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    load_indices_from_storage,\n",
    "    load_graph_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8291822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17dd9f9d-7e21-49ef-9a01-d8b0dd7fdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9954a1",
   "metadata": {},
   "source": [
    "# Set LLM (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a66b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add api key to llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f9e96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-4o\", max_tokens=3000)\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d7bc2",
   "metadata": {},
   "source": [
    "# Set local LLM for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa4bc549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "#Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a4b82",
   "metadata": {},
   "source": [
    "# Set LLM for chat  (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d46a1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = Ollama(model=\"tinyllama\", request_timeout=120.0)\n",
    "#Settings.llm = llm\n",
    "#Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc9d70",
   "metadata": {},
   "source": [
    "# Test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d810955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "assistant: As a data governance consultant, I don't have personal preferences or favorites. However, I can tell you about some popular data tools that are widely used in the industry for various purposes:\n",
      "\n",
      "1. **Data Governance Platforms**: Tools like Collibra and Informatica offer comprehensive solutions for managing data governance, including data cataloging, data lineage, and policy management.\n",
      "\n",
      "2. **Data Quality Tools**: Talend and Trifacta are popular for ensuring data quality by providing features for data cleansing, profiling, and transformation.\n",
      "\n",
      "3. **Data Catalogs**: Alation and Data.world are known for their robust data cataloging capabilities, helping organizations discover and manage their data assets effectively.\n",
      "\n",
      "4. **Data Integration Tools**: Apache NiFi and MuleSoft are widely used for data integration, allowing seamless data flow between different systems and applications.\n",
      "\n",
      "5. **Data Privacy Tools**: Tools like OneTrust and BigID help organizations manage data privacy and compliance with regulations like GDPR and CCPA.\n",
      "\n",
      "Each of these tools has its strengths and is chosen based on the specific needs and context of an organization.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a data governance consultant\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What's your favorite data tool ?\"),\n",
    "]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47252b4e-eb58-453c-9e7d-bab5286ee296",
   "metadata": {},
   "source": [
    "# Load storage contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e8019-e150-4a60-b59d-cac7a4aebcba",
   "metadata": {},
   "source": [
    "## Load vector storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "42c55a04-2b21-4c05-96fb-f0f9ce26bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"vector\"),\n",
    "    vector_store=SimpleVectorStore.from_persist_dir(\n",
    "        persist_dir=\"vector\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"vector\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b951a-9776-46da-9309-142acfc3f1dd",
   "metadata": {},
   "source": [
    "## Load knowledge graph storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a086ef48-3be3-4a12-b158-4ed50aa2b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"knowledge_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28317dfb",
   "metadata": {},
   "source": [
    "## Load onto graph storage context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db73d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"onto_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6d278b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x000001DB33F79400>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x000001DB33F8D910>, vector_stores={'default': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={})), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x000001DB33F8DD00>, property_graph_store=None)\n"
     ]
    }
   ],
   "source": [
    "print(onto_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c3f5b-f0fa-4e10-85fd-9ff7642de428",
   "metadata": {},
   "source": [
    "# Load index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3e85a-8fca-4138-9ff9-fca4637a47e2",
   "metadata": {},
   "source": [
    "## Load vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "68274006-61a7-42d7-9556-6ddae87d2b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "simple_index = load_index_from_storage(vector_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdab09-2c63-4e23-9ca3-79102db74cf0",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6c3e925-229f-4636-a7b7-73687a3aa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b32a3",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "887f57e4-8bc9-440b-a84c-0080cbd412e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863445ebffe341088988f6eecdd21819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "simple_rag_retriever = simple_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = simple_query_engine.query(\n",
    "    \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f014fd60-81a4-4b7f-aef9-f545402e0fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, une approche structurée peut être suivie. Voici un plan détaillé :\n",
       "\n",
       "1. **Compréhension du problème :**\n",
       "   - Définir clairement l'objectif de la prédiction.\n",
       "   - Identifier les variables cibles et explicatives.\n",
       "\n",
       "2. **Collecte et préparation des données :**\n",
       "   - Rassembler les données historiques des clients, y compris les informations démographiques, financières, et comportementales.\n",
       "   - Nettoyer les données pour gérer les valeurs manquantes et les anomalies.\n",
       "   - Effectuer une analyse exploratoire des données pour comprendre les distributions et les relations entre les variables.\n",
       "\n",
       "3. **Sélection de la méthode de modélisation :**\n",
       "   - Choisir une méthode de classification, car le problème est de nature binaire (défaut ou non).\n",
       "   - Considérer des algorithmes comme la régression logistique, les arbres de décision, les forêts aléatoires, ou les machines à vecteurs de support.\n",
       "\n",
       "4. **Construction du modèle :**\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "   - Entraîner le modèle choisi sur l'ensemble d'entraînement.\n",
       "   - Optimiser les hyperparamètres pour améliorer la performance du modèle.\n",
       "\n",
       "5. **Évaluation du modèle :**\n",
       "   - Utiliser des métriques de performance telles que l'accuracy, le F1-score, la précision, et le rappel pour évaluer le modèle.\n",
       "   - Effectuer une validation croisée pour assurer la robustesse du modèle.\n",
       "\n",
       "6. **Interprétation et déploiement :**\n",
       "   - Analyser les résultats pour comprendre les facteurs influençant le défaut.\n",
       "   - Déployer le modèle dans un environnement de production pour des prédictions en temps réel.\n",
       "\n",
       "7. **Surveillance et mise à jour :**\n",
       "   - Surveiller la performance du modèle au fil du temps.\n",
       "   - Mettre à jour le modèle régulièrement avec de nouvelles données pour maintenir sa précision.\n",
       "\n",
       "Ce plan fournit une approche systématique pour prédire le défaut de paiement d'un client sur un prêt bancaire.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242ad8d-20fb-4126-9380-4d51c7e3fa32",
   "metadata": {},
   "source": [
    "## Load graph index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "75e3c260-c349-43f0-b54c-6dac7a12586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "graph_index = load_index_from_storage(graph_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81c1e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8424ed30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 6\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0388bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 9 nodes and 6 edges\n",
      "Nodes: ['Model', 'Parent', 'Type_model', 'Classification', 'Clustering', 'Regression', 'Prediction', 'Type_algo', 'Optimization algorithm']\n",
      "Edges: [('Model', 'Parent'), ('Type_model', 'Classification'), ('Type_model', 'Clustering'), ('Type_model', 'Regression'), ('Type_model', 'Prediction'), ('Type_algo', 'Optimization algorithm')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d6f30",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "330e38ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e323b",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c0dd0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e87f96b3d404de890ec82a6a9e6660e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 20e84990-8d4c-41ad-a31d-62a63edd8a65: ---\n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "usage: \"[[Prediction]]\"\n",
      "---\n",
      "> Querying with idx: 20e84990-8d4c-41ad-a31d-62a63edd8a65: ---\n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "usage: \"[[Prediction]]\"\n",
      "---\n",
      "> Querying with idx: 20e84990-8d4c-41ad-a31d-62a63edd8a65: ---\n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "usage: \"[[Prediction]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 4a3c46d4-923d-473c-9f33-b7c104a81217: ---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classificati...\n",
      "> Querying with idx: 4a3c46d4-923d-473c-9f33-b7c104a81217: ---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classificati...\n",
      "> Querying with idx: 4a3c46d4-923d-473c-9f33-b7c104a81217: ---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classificati...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7ec05980-7510-4ca8-bb6c-7a4d13b52215: ---\n",
      "used by: \n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "---\n",
      "> Querying with idx: 7ec05980-7510-4ca8-bb6c-7a4d13b52215: ---\n",
      "used by: \n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "---\n",
      "> Querying with idx: 7ec05980-7510-4ca8-bb6c-7a4d13b52215: ---\n",
      "used by: \n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 34355420-d17b-4534-b492-ade4a9ad7720: ---\n",
      "type_model:\n",
      "  - \"[[Classification]]\"\n",
      "---\n",
      "> Querying with idx: 34355420-d17b-4534-b492-ade4a9ad7720: ---\n",
      "type_model:\n",
      "  - \"[[Classification]]\"\n",
      "---\n",
      "> Querying with idx: 34355420-d17b-4534-b492-ade4a9ad7720: ---\n",
      "type_model:\n",
      "  - \"[[Classification]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 586681f4-8f47-4aef-a419-98adfbf8329d: ---\n",
      "type_algo: \"[[Optimization algorithm]]\"\n",
      "---\n",
      "> Querying with idx: 586681f4-8f47-4aef-a419-98adfbf8329d: ---\n",
      "type_algo: \"[[Optimization algorithm]]\"\n",
      "---\n",
      "> Querying with idx: 586681f4-8f47-4aef-a419-98adfbf8329d: ---\n",
      "type_algo: \"[[Optimization algorithm]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2f7adc91-9550-4d75-9e56-13cf02007eb0: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "> Querying with idx: 2f7adc91-9550-4d75-9e56-13cf02007eb0: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "> Querying with idx: 2f7adc91-9550-4d75-9e56-13cf02007eb0: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: be73ac4e-23a7-47c8-baf1-799c46e41acb: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "> Querying with idx: be73ac4e-23a7-47c8-baf1-799c46e41acb: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "> Querying with idx: be73ac4e-23a7-47c8-baf1-799c46e41acb: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 35ade69a-6631-474e-9bc8-c8edfe0bfd5a: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "> Querying with idx: 35ade69a-6631-474e-9bc8-c8edfe0bfd5a: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "> Querying with idx: 35ade69a-6631-474e-9bc8-c8edfe0bfd5a: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "graph_rag_retriever = graph_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(\n",
    "    \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d1031a44-f06e-400f-beaa-2065beeee9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, une méthode de classification serait appropriée. Voici un plan pour aborder ce problème :\n",
       "\n",
       "1. **Collecte des données**: Rassemblez des données historiques sur les clients, y compris des informations démographiques, des antécédents de crédit, des revenus, etc.\n",
       "\n",
       "2. **Prétraitement des données**: Nettoyez les données en traitant les valeurs manquantes, en normalisant les variables et en encodant les variables catégorielles.\n",
       "\n",
       "3. **Sélection des caractéristiques**: Identifiez les caractéristiques les plus pertinentes qui influencent le défaut de paiement à l'aide de techniques de sélection de caractéristiques.\n",
       "\n",
       "4. **Choix du modèle**: Utilisez un modèle de classification, tel que la régression logistique, les arbres de décision, ou les forêts aléatoires, pour prédire le défaut de paiement.\n",
       "\n",
       "5. **Entraînement du modèle**: Divisez les données en ensembles d'entraînement et de test, puis entraînez le modèle sur l'ensemble d'entraînement.\n",
       "\n",
       "6. **Évaluation du modèle**: Évaluez la performance du modèle à l'aide de l'ensemble de test en utilisant des métriques telles que la précision, le rappel, et la courbe ROC.\n",
       "\n",
       "7. **Optimisation**: Affinez le modèle en ajustant les hyperparamètres pour améliorer sa performance.\n",
       "\n",
       "8. **Déploiement**: Intégrez le modèle dans le système de décision pour prédire le risque de défaut des nouveaux clients.\n",
       "\n",
       "9. **Surveillance et mise à jour**: Surveillez la performance du modèle et mettez-le à jour régulièrement avec de nouvelles données pour maintenir sa précision.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e7541",
   "metadata": {},
   "source": [
    "## Load onto index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bb203e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(persist_dir=\"onto_graph\")\n",
    "# Load the PropertyGraphIndex from the storage context\n",
    "\n",
    "onto_index = load_index_from_storage(onto_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a182d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_index.property_graph_store.save_networkx_graph(\n",
    "    name=\"OntoGraph.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4dcae",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bee17732",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95920ba",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4c400086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9763131b78a448a8bb71c69f6f879ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "onto_rag_retriever = onto_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(\n",
    "    \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "123366e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, il est approprié d'utiliser une méthode de classification. Voici un plan pour aborder ce problème :\n",
       "\n",
       "1. **Compréhension du problème :**\n",
       "   - Définir clairement l'objectif : prédire le défaut de paiement.\n",
       "   - Identifier les variables cibles et explicatives.\n",
       "\n",
       "2. **Collecte et préparation des données :**\n",
       "   - Rassembler les données historiques des clients, y compris les caractéristiques démographiques, financières, et comportementales.\n",
       "   - Nettoyer les données pour gérer les valeurs manquantes et les anomalies.\n",
       "\n",
       "3. **Exploration des données :**\n",
       "   - Analyser les données pour comprendre les distributions et les relations entre les variables.\n",
       "   - Utiliser des visualisations pour identifier les tendances et les corrélations.\n",
       "\n",
       "4. **Sélection des caractéristiques :**\n",
       "   - Choisir les variables les plus pertinentes pour la prédiction.\n",
       "   - Éventuellement, réduire la dimensionnalité avec des techniques comme l'analyse en composantes principales (PCA).\n",
       "\n",
       "5. **Choix du modèle de classification :**\n",
       "   - Considérer des modèles tels que la régression logistique, les arbres de décision, les forêts aléatoires, ou les machines à vecteurs de support (SVM).\n",
       "   - Comparer les modèles en termes de précision, de rappel, et de courbe ROC.\n",
       "\n",
       "6. **Entraînement et validation du modèle :**\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "   - Entraîner le modèle sur l'ensemble d'entraînement.\n",
       "   - Valider le modèle avec l'ensemble de test pour évaluer sa performance.\n",
       "\n",
       "7. **Optimisation du modèle :**\n",
       "   - Ajuster les hyperparamètres pour améliorer la performance.\n",
       "   - Utiliser des techniques de validation croisée pour éviter le surapprentissage.\n",
       "\n",
       "8. **Interprétation et déploiement :**\n",
       "   - Interpréter les résultats pour comprendre les facteurs influençant le défaut de paiement.\n",
       "   - Déployer le modèle dans un environnement de production pour des prédictions en temps réel.\n",
       "\n",
       "9. **Suivi et mise à jour :**\n",
       "   - Surveiller la performance du modèle au fil du temps.\n",
       "   - Mettre à jour le modèle avec de nouvelles données pour maintenir sa précision. \n",
       "\n",
       "Ce plan vous guidera dans la mise en œuvre d'une solution de classification pour prédire le défaut de paiement des clients.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b65be-955e-44db-942e-27e235384f19",
   "metadata": {},
   "source": [
    "# Visualize knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "55ef03a2-2e7e-443d-865f-b6d991d16416",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b9d58e14-0017-494f-98ec-ad8b30bf8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 6\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a113918c-f195-4c8c-b0f3-c85d7a6c5d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 9 nodes and 6 edges\n",
      "Nodes: ['Model', 'Parent', 'Type_model', 'Classification', 'Clustering', 'Regression', 'Prediction', 'Type_algo', 'Optimization algorithm']\n",
      "Edges: [('Model', 'Parent'), ('Type_model', 'Classification'), ('Type_model', 'Clustering'), ('Type_model', 'Regression'), ('Type_model', 'Prediction'), ('Type_algo', 'Optimization algorithm')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab94fc0-2080-4869-94a0-b013dc0fbd9d",
   "metadata": {},
   "source": [
    "# (Simple) Query the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6c93bdbb-aaa4-4658-aecf-1cd7b5038ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd9891258824d83b2717948d2ab876a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\"\n",
    "query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e2a871b4-70c8-45ed-a8b9-b2aaa8d15a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, une approche structurée peut être suivie. Voici un plan détaillé :\n",
       "\n",
       "1. **Compréhension du problème :**\n",
       "   - Définir clairement l'objectif de la prédiction.\n",
       "   - Identifier les variables cibles et explicatives.\n",
       "\n",
       "2. **Collecte et préparation des données :**\n",
       "   - Rassembler les données historiques des clients, y compris les informations démographiques, financières, et comportementales.\n",
       "   - Nettoyer les données pour gérer les valeurs manquantes et les anomalies.\n",
       "   - Effectuer une analyse exploratoire des données pour comprendre les distributions et les relations.\n",
       "\n",
       "3. **Choix de la méthode de modélisation :**\n",
       "   - Utiliser une méthode de classification, car le problème est de nature binaire (défaut ou non).\n",
       "   - Considérer des algorithmes comme la régression logistique, les arbres de décision, ou les forêts aléatoires.\n",
       "\n",
       "4. **Construction du modèle :**\n",
       "   - Diviser les données en ensembles d'entraînement et de test.\n",
       "   - Entraîner le modèle choisi sur l'ensemble d'entraînement.\n",
       "   - Ajuster les hyperparamètres pour optimiser les performances.\n",
       "\n",
       "5. **Évaluation du modèle :**\n",
       "   - Utiliser des métriques telles que l'accuracy, le rappel, la précision, et l'AUC-ROC pour évaluer la performance du modèle.\n",
       "   - Comparer les performances de différents modèles pour choisir le meilleur.\n",
       "\n",
       "6. **Interprétation et déploiement :**\n",
       "   - Interpréter les résultats pour comprendre les facteurs influençant le défaut.\n",
       "   - Déployer le modèle dans un environnement de production pour des prédictions en temps réel.\n",
       "\n",
       "7. **Suivi et mise à jour :**\n",
       "   - Surveiller la performance du modèle au fil du temps.\n",
       "   - Mettre à jour le modèle avec de nouvelles données pour maintenir sa précision.\n",
       "\n",
       "Ce plan permet de structurer le processus de prédiction de manière efficace et rigoureuse.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099031c-b137-468f-b20c-9c6fab1c4eb1",
   "metadata": {},
   "source": [
    "# (Simple) Query the knowledge graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8948dd2b-acd4-4621-a2d1-b45034a21007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35233b21f8b4fdea50bdbb1ea55bb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 20e84990-8d4c-41ad-a31d-62a63edd8a65: ---\n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "usage: \"[[Prediction]]\"\n",
      "---\n",
      "> Querying with idx: 20e84990-8d4c-41ad-a31d-62a63edd8a65: ---\n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "usage: \"[[Prediction]]\"\n",
      "---\n",
      "> Querying with idx: 20e84990-8d4c-41ad-a31d-62a63edd8a65: ---\n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "usage: \"[[Prediction]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 4a3c46d4-923d-473c-9f33-b7c104a81217: ---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classificati...\n",
      "> Querying with idx: 4a3c46d4-923d-473c-9f33-b7c104a81217: ---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classificati...\n",
      "> Querying with idx: 4a3c46d4-923d-473c-9f33-b7c104a81217: ---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classificati...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7ec05980-7510-4ca8-bb6c-7a4d13b52215: ---\n",
      "used by: \n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "---\n",
      "> Querying with idx: 7ec05980-7510-4ca8-bb6c-7a4d13b52215: ---\n",
      "used by: \n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "---\n",
      "> Querying with idx: 7ec05980-7510-4ca8-bb6c-7a4d13b52215: ---\n",
      "used by: \n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 34355420-d17b-4534-b492-ade4a9ad7720: ---\n",
      "type_model:\n",
      "  - \"[[Classification]]\"\n",
      "---\n",
      "> Querying with idx: 34355420-d17b-4534-b492-ade4a9ad7720: ---\n",
      "type_model:\n",
      "  - \"[[Classification]]\"\n",
      "---\n",
      "> Querying with idx: 34355420-d17b-4534-b492-ade4a9ad7720: ---\n",
      "type_model:\n",
      "  - \"[[Classification]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 586681f4-8f47-4aef-a419-98adfbf8329d: ---\n",
      "type_algo: \"[[Optimization algorithm]]\"\n",
      "---\n",
      "> Querying with idx: 586681f4-8f47-4aef-a419-98adfbf8329d: ---\n",
      "type_algo: \"[[Optimization algorithm]]\"\n",
      "---\n",
      "> Querying with idx: 586681f4-8f47-4aef-a419-98adfbf8329d: ---\n",
      "type_algo: \"[[Optimization algorithm]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2f7adc91-9550-4d75-9e56-13cf02007eb0: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "> Querying with idx: 2f7adc91-9550-4d75-9e56-13cf02007eb0: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "> Querying with idx: 2f7adc91-9550-4d75-9e56-13cf02007eb0: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: be73ac4e-23a7-47c8-baf1-799c46e41acb: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "> Querying with idx: be73ac4e-23a7-47c8-baf1-799c46e41acb: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "> Querying with idx: be73ac4e-23a7-47c8-baf1-799c46e41acb: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 35ade69a-6631-474e-9bc8-c8edfe0bfd5a: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "> Querying with idx: 35ade69a-6631-474e-9bc8-c8edfe0bfd5a: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "> Querying with idx: 35ade69a-6631-474e-9bc8-c8edfe0bfd5a: ---\n",
      "parent: \"[[Model]]\"\n",
      "---\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan\"\n",
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ff5382fd-1fc8-4faf-9356-c9bb3e478db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, une méthode de classification est appropriée. Voici un plan pour aborder ce problème :\n",
       "\n",
       "1. **Collecte des données**: Rassemblez des données historiques sur les clients, y compris des informations démographiques, des antécédents de crédit, des revenus, etc.\n",
       "\n",
       "2. **Prétraitement des données**: Nettoyez les données en traitant les valeurs manquantes, en normalisant les variables et en encodant les variables catégorielles.\n",
       "\n",
       "3. **Sélection des caractéristiques**: Identifiez les caractéristiques les plus pertinentes qui influencent la probabilité de défaut.\n",
       "\n",
       "4. **Choix du modèle**: Utilisez un modèle de classification, tel que la régression logistique, les arbres de décision, ou les forêts aléatoires, pour prédire le défaut.\n",
       "\n",
       "5. **Entraînement du modèle**: Divisez les données en ensembles d'entraînement et de test, puis entraînez le modèle sur l'ensemble d'entraînement.\n",
       "\n",
       "6. **Évaluation du modèle**: Évaluez la performance du modèle à l'aide de l'ensemble de test en utilisant des métriques telles que la précision, le rappel, et la courbe ROC.\n",
       "\n",
       "7. **Optimisation**: Ajustez les hyperparamètres du modèle pour améliorer sa performance.\n",
       "\n",
       "8. **Déploiement**: Intégrez le modèle dans le système de décision pour prédire le risque de défaut des nouveaux clients.\n",
       "\n",
       "9. **Surveillance et mise à jour**: Surveillez la performance du modèle et mettez-le à jour régulièrement avec de nouvelles données pour maintenir sa précision.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef119d0",
   "metadata": {},
   "source": [
    "# (Simple) Query the onto graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a8db6420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b298f52a587649a9bf84ec49ea03f985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire. Fais moi un plan.\"\n",
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=2,\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "adcd4265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Pour prédire si un client va faire défaut sur son prêt bancaire, il est approprié d'utiliser une méthode de classification. Voici un plan pour aborder ce problème :\n",
       "\n",
       "1. **Collecte des données**: Rassembler des données historiques sur les clients, y compris des informations démographiques, financières, et des antécédents de crédit.\n",
       "\n",
       "2. **Prétraitement des données**:\n",
       "   - Nettoyage des données pour gérer les valeurs manquantes et les anomalies.\n",
       "   - Normalisation ou standardisation des variables si nécessaire.\n",
       "   - Encodage des variables catégorielles.\n",
       "\n",
       "3. **Séparation des données**:\n",
       "   - Diviser les données en ensembles d'entraînement et de test pour évaluer la performance du modèle.\n",
       "\n",
       "4. **Choix du modèle de classification**:\n",
       "   - Sélectionner un ou plusieurs algorithmes de classification, tels que la régression logistique, les arbres de décision, ou les forêts aléatoires.\n",
       "\n",
       "5. **Entraînement du modèle**:\n",
       "   - Utiliser l'ensemble d'entraînement pour ajuster le modèle choisi.\n",
       "\n",
       "6. **Évaluation du modèle**:\n",
       "   - Tester le modèle sur l'ensemble de test.\n",
       "   - Utiliser des métriques telles que la précision, le rappel, et la courbe ROC pour évaluer la performance.\n",
       "\n",
       "7. **Optimisation**:\n",
       "   - Ajuster les hyperparamètres pour améliorer la performance du modèle.\n",
       "   - Envisager l'utilisation de techniques d'ensemble pour combiner plusieurs modèles.\n",
       "\n",
       "8. **Déploiement**:\n",
       "   - Mettre en place le modèle dans un environnement de production pour prédire les défauts de paiement des nouveaux clients.\n",
       "\n",
       "9. **Surveillance et mise à jour**:\n",
       "   - Surveiller la performance du modèle au fil du temps et le mettre à jour avec de nouvelles données pour maintenir sa précision.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582274ba",
   "metadata": {},
   "source": [
    "## (Node retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "16db2a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4498fc6495420cb12ee7ba30b686f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classification]]\"\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "retriever = onto_index.as_retriever(\n",
    "    include_text=True,  # include source text, default True\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"Quelle méthode utiliser pour prédire si un client va faire défaut sur son prêt bancaire ?\")\n",
    "\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a895520-d196-476f-b569-69a67484c120",
   "metadata": {},
   "source": [
    "# Have a real chat with your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3764d-a084-4f36-9d8c-3613aa9fd835",
   "metadata": {},
   "source": [
    "## Set up the engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e55a2-a9a9-4c4e-89a4-c4dfba55ebe4",
   "metadata": {},
   "source": [
    "### Vector engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1581c90c-cf5a-40d3-81b0-086238068f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "vector_chat_engine = simple_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \" \"\n",
    "        \" \"\n",
    "        \".\"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a1c22-111b-4793-8a3d-bd3eae7e3ec7",
   "metadata": {},
   "source": [
    "### Graph engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98b73cc2-0588-4b96-9aa2-1dfaf4cadb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897ec22",
   "metadata": {},
   "source": [
    "### Onto engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "54d04e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onto_chat_engine = onto_index.query_engine(\n",
    "#    chat_mode=\"condense_plus_context\",\n",
    "#    llm=llm\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e0a08-f6ff-4ee6-a165-9b9fd90621fa",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "12804e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chat_engine.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "709a37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \" \"\n",
    "        \" \"\n",
    "        \" \"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "da3e3ebf-18dc-4bdc-87dc-58d0227e9c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: \n",
      "Condensed question: \n",
      "Condensed question: \n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd767c6d50ff4e2ba6651c6dbb8ff1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 4a3c46d4-923d-473c-9f33-b7c104a81217: ---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classificati...\n",
      "> Querying with idx: 4a3c46d4-923d-473c-9f33-b7c104a81217: ---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classificati...\n",
      "> Querying with idx: 4a3c46d4-923d-473c-9f33-b7c104a81217: ---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classificati...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 34355420-d17b-4534-b492-ade4a9ad7720: ---\n",
      "type_model:\n",
      "  - \"[[Classification]]\"\n",
      "---\n",
      "> Querying with idx: 34355420-d17b-4534-b492-ade4a9ad7720: ---\n",
      "type_model:\n",
      "  - \"[[Classification]]\"\n",
      "---\n",
      "> Querying with idx: 34355420-d17b-4534-b492-ade4a9ad7720: ---\n",
      "type_model:\n",
      "  - \"[[Classification]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 20e84990-8d4c-41ad-a31d-62a63edd8a65: ---\n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "usage: \"[[Prediction]]\"\n",
      "---\n",
      "> Querying with idx: 20e84990-8d4c-41ad-a31d-62a63edd8a65: ---\n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "usage: \"[[Prediction]]\"\n",
      "---\n",
      "> Querying with idx: 20e84990-8d4c-41ad-a31d-62a63edd8a65: ---\n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "usage: \"[[Prediction]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7ec05980-7510-4ca8-bb6c-7a4d13b52215: ---\n",
      "used by: \n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "---\n",
      "> Querying with idx: 7ec05980-7510-4ca8-bb6c-7a4d13b52215: ---\n",
      "used by: \n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "---\n",
      "> Querying with idx: 7ec05980-7510-4ca8-bb6c-7a4d13b52215: ---\n",
      "used by: \n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "91ebf21f-1990-4a4d-9c9a-868872f03042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Hello! How can I assist you today?"
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5a056a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6660a81e-ad67-4d44-a86d-0ad7b77f626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_modele = \"\"\" \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9c0e462e-d3ee-463a-8d49-f09dc2396b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: Pouvez-vous imiter le style d'écriture de la section modèle ?\n",
      "Condensed question: Pouvez-vous imiter le style d'écriture de la section modèle ?\n",
      "Condensed question: Pouvez-vous imiter le style d'écriture de la section modèle ?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e510171c88a477dad64ac486187b275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 4a3c46d4-923d-473c-9f33-b7c104a81217: ---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classificati...\n",
      "> Querying with idx: 4a3c46d4-923d-473c-9f33-b7c104a81217: ---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classificati...\n",
      "> Querying with idx: 4a3c46d4-923d-473c-9f33-b7c104a81217: ---\n",
      "type_model:\n",
      "  - \"[[Clustering]]\"\n",
      "  - \"[[Regression]]\"\n",
      "  - \"[[Classificati...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 34355420-d17b-4534-b492-ade4a9ad7720: ---\n",
      "type_model:\n",
      "  - \"[[Classification]]\"\n",
      "---\n",
      "> Querying with idx: 34355420-d17b-4534-b492-ade4a9ad7720: ---\n",
      "type_model:\n",
      "  - \"[[Classification]]\"\n",
      "---\n",
      "> Querying with idx: 34355420-d17b-4534-b492-ade4a9ad7720: ---\n",
      "type_model:\n",
      "  - \"[[Classification]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 20e84990-8d4c-41ad-a31d-62a63edd8a65: ---\n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "usage: \"[[Prediction]]\"\n",
      "---\n",
      "> Querying with idx: 20e84990-8d4c-41ad-a31d-62a63edd8a65: ---\n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "usage: \"[[Prediction]]\"\n",
      "---\n",
      "> Querying with idx: 20e84990-8d4c-41ad-a31d-62a63edd8a65: ---\n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "usage: \"[[Prediction]]\"\n",
      "---\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7ec05980-7510-4ca8-bb6c-7a4d13b52215: ---\n",
      "used by: \n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "---\n",
      "> Querying with idx: 7ec05980-7510-4ca8-bb6c-7a4d13b52215: ---\n",
      "used by: \n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "---\n",
      "> Querying with idx: 7ec05980-7510-4ca8-bb6c-7a4d13b52215: ---\n",
      "used by: \n",
      "type_model:\n",
      "  - \"[[Regression]]\"\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"Imite le style d'écriture de la {section_modele}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c86075ee-12c8-4b97-8b51-0c717fc4b1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Je suis désolé, mais il semble qu'il y ait eu une petite confusion dans votre demande. Pourriez-vous préciser quel style d'écriture ou quel modèle vous aimeriez que j'imite ? Cela m'aiderait à mieux répondre à votre demande. Merci !"
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ffb78d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74a302-bb28-4bf8-9103-1f62750a5fc0",
   "metadata": {},
   "source": [
    "## Sum-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d81f7480-9d62-4952-948e-19e089d9da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = memory.get_all()\n",
    "\n",
    "# Assuming chat_history is available and contains your messages\n",
    "assistant_messages = [\n",
    "    message.content \n",
    "    for message in chat_history \n",
    "    if message.role == MessageRole.ASSISTANT  # Compare with the enum directly\n",
    "]\n",
    "\n",
    "\n",
    "output_filename = r\"C:\\Users\\asarazin\\OneDrive - Veltys Max\\Documents\\documente-marcel\\output\\output.md\"\n",
    "# Write to a Markdown file\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    for msg in assistant_messages:\n",
    "        f.write(msg + \"\\n\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
