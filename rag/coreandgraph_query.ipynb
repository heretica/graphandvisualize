{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "45492c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.12.8)\n",
      "Requirement already satisfied: llama-index-readers-obsidian in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: ipywidgets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (8.1.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (4.67.1)\n",
      "Requirement already satisfied: ipython in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (8.18.1)\n",
      "Requirement already satisfied: huggingface-hub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.24.0)\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (1.58.1)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (6.0.1)\n",
      "Requirement already satisfied: llama-index-llms-ollama in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (0.5.0)\n",
      "Requirement already satisfied: llama-index-embeddings-ollama in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.5.0)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: ipykernel in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (6.27.1)\n",
      "Requirement already satisfied: pyvis in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (0.3.2)\n",
      "Requirement already satisfied: python-dotenv in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from -r requirements.txt (line 14)) (1.0.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.12.8)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.12)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index->-r requirements.txt (line 1)) (3.9.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (5.14.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipywidgets->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: decorator in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython->-r requirements.txt (line 5)) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from ipython->-r requirements.txt (line 5)) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython->-r requirements.txt (line 5)) (3.0.41)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython->-r requirements.txt (line 5)) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython->-r requirements.txt (line 5)) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipython->-r requirements.txt (line 5)) (4.9.0)\n",
      "Requirement already satisfied: filelock in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (23.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->-r requirements.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 7)) (4.1.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 7)) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai->-r requirements.txt (line 7)) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from openai->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: ollama>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-llms-ollama->-r requirements.txt (line 9)) (0.4.4)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.3.1)\n",
      "Requirement already satisfied: appnope in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from ipykernel->-r requirements.txt (line 12)) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (8.6.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (5.5.0)\n",
      "Requirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (1.5.8)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (5.9.6)\n",
      "Requirement already satisfied: pyzmq>=20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from ipykernel->-r requirements.txt (line 12)) (6.4)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyvis->-r requirements.txt (line 13)) (3.1.4)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyvis->-r requirements.txt (line 13)) (3.2.2)\n",
      "Requirement already satisfied: networkx>=1.11 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pyvis->-r requirements.txt (line 13)) (3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 7)) (3.6)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (0.14.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.11.11)\n",
      "Requirement already satisfied: minijinja>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.5.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from jedi>=0.16->ipython->-r requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from jinja2>=2.9.6->pyvis->-r requirements.txt (line 13)) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 12)) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 12)) (4.1.0)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (2.0.32)\n",
      "Requirement already satisfied: dataclasses-json in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.2.15)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.24.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (10.2.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (8.2.2)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: llama-cloud>=0.1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (4.12.3)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (1.5.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (5.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 1)) (0.5.18)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from nltk>3.8.1->llama-index->-r requirements.txt (line 1)) (2023.8.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from pexpect>4.3->ipython->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->-r requirements.txt (line 5)) (0.2.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 7)) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub->-r requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (4.42.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: scipy in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.11.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython->-r requirements.txt (line 5)) (0.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (6.0.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.18.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from asttokens>=2.1.0->stack-data->ipython->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (2.0.2)\n",
      "Requirement already satisfied: sympy in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.12)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (0.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.8->llama-index->-r requirements.txt (line 1)) (3.23.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (3.5.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/arthursarazin/Library/Python/3.11/lib/python/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface->-r requirements.txt (line 11)) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "614fc4e2-0e04-49b0-bf7c-05efee48933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.obsidian import ObsidianReader\n",
    "from llama_index.core.memory.chat_memory_buffer import MessageRole\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex, VectorStoreIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import Document, PropertyGraphIndex\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "import logging\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    SimpleLLMPathExtractor,\n",
    "    SchemaLLMPathExtractor,\n",
    "    DynamicLLMPathExtractor,\n",
    ")\n",
    "import yaml\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b5e9f925-0bd9-406c-a41d-8be268260b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    load_indices_from_storage,\n",
    "    load_graph_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8291822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "17dd9f9d-7e21-49ef-9a01-d8b0dd7fdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9954a1",
   "metadata": {},
   "source": [
    "# Set LLM (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3a66b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Charge les variables depuis le fichier .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY_UP\")\n",
    "# Modifier ou ajouter une variable d'environnement\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6f9e96ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-4o\", max_tokens=3000)\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d7bc2",
   "metadata": {},
   "source": [
    "# Set local LLM for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aa4bc549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "#Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a4b82",
   "metadata": {},
   "source": [
    "# Set LLM for chat  (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d46a1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = Ollama(model=\"tinyllama\", request_timeout=120.0)\n",
    "#Settings.llm = llm\n",
    "#Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc9d70",
   "metadata": {},
   "source": [
    "# Test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d810955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "assistant: As a data governance consultant, I don't have personal preferences or feelings. However, I can provide insights into popular data tools that are widely used in the industry for data governance purposes. Some of these include:\n",
      "\n",
      "1. **Collibra**: Known for its comprehensive data governance platform, Collibra helps organizations manage data assets, ensure data quality, and maintain compliance with regulations.\n",
      "\n",
      "2. **Informatica**: Offers a suite of data governance tools that include data cataloging, data quality, and master data management, helping organizations to streamline their data governance processes.\n",
      "\n",
      "3. **Alation**: A leader in data cataloging, Alation provides tools for data discovery, governance, and collaboration, making it easier for organizations to manage their data assets.\n",
      "\n",
      "4. **Talend**: Provides data integration and data quality tools that support data governance initiatives by ensuring data accuracy and consistency across the organization.\n",
      "\n",
      "5. **IBM InfoSphere**: Offers a range of data governance solutions, including data quality, data integration, and master data management, to help organizations manage their data effectively.\n",
      "\n",
      "6. **Microsoft Purview**: A unified data governance solution that helps organizations manage and govern their on-premises, multi-cloud, and software-as-a-service (SaaS) data.\n",
      "\n",
      "Each of these tools has its strengths and is chosen based on the specific needs and infrastructure of an organization.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a data governance consultant\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What's your favorite data tool ?\"),\n",
    "]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47252b4e-eb58-453c-9e7d-bab5286ee296",
   "metadata": {},
   "source": [
    "# Load storage contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e8019-e150-4a60-b59d-cac7a4aebcba",
   "metadata": {},
   "source": [
    "## Load vector storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "42c55a04-2b21-4c05-96fb-f0f9ce26bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"vector\"),\n",
    "    vector_store=SimpleVectorStore.from_persist_dir(\n",
    "        persist_dir=\"vector\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"vector\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b951a-9776-46da-9309-142acfc3f1dd",
   "metadata": {},
   "source": [
    "## Load knowledge graph storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a086ef48-3be3-4a12-b158-4ed50aa2b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"knowledge_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"knowledge_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28317dfb",
   "metadata": {},
   "source": [
    "## Load onto graph storage context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "db73d4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(\n",
    "    docstore=SimpleDocumentStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    "    graph_store=SimpleGraphStore.from_persist_dir(\n",
    "        persist_dir=\"onto_graph\"\n",
    "    ),\n",
    "    index_store=SimpleIndexStore.from_persist_dir(persist_dir=\"onto_graph\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6d278b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x2c678df90>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x2a2ae4810>, vector_stores={'default': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={})), 'image': SimpleVectorStore(stores_text=False, is_embedding_query=True, data=SimpleVectorStoreData(embedding_dict={}, text_id_to_ref_doc_id={}, metadata_dict={}))}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x2c0bbd910>, property_graph_store=None)\n"
     ]
    }
   ],
   "source": [
    "print(onto_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c3f5b-f0fa-4e10-85fd-9ff7642de428",
   "metadata": {},
   "source": [
    "# Load index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb3e85a-8fca-4138-9ff9-fca4637a47e2",
   "metadata": {},
   "source": [
    "## Load vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "68274006-61a7-42d7-9556-6ddae87d2b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "simple_index = load_index_from_storage(vector_storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cdab09-2c63-4e23-9ca3-79102db74cf0",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a6c3e925-229f-4636-a7b7-73687a3aa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b32a3",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "887f57e4-8bc9-440b-a84c-0080cbd412e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78f00e7dbdc4d7c8184cf7c2765a90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "simple_rag_retriever = simple_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = simple_query_engine.query(\n",
    "    \"Qui est-tu ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f014fd60-81a4-4b7f-aef9-f545402e0fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Je suis un système de questions-réponses conçu pour fournir des réponses précises et fiables en utilisant les informations disponibles.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242ad8d-20fb-4126-9380-4d51c7e3fa32",
   "metadata": {},
   "source": [
    "## Load graph index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "75e3c260-c349-43f0-b54c-6dac7a12586f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "graph_index = load_index_from_storage(graph_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "81c1e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8424ed30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in the knowledge graph: 60\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of edges in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0388bce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 94 nodes and 60 edges\n",
      "Nodes: ['Exactitude', 'Justes et cohérentes', 'Complétude', 'Complet', 'Nettoyage', 'Erreurs', 'Normalisation', 'Formats', 'Florence nightingale', 'Infirmière britannique', \"Présentation visuelle de l'information\", 'Dataviz project', 'Relation', 'Bibliothèque', 'Description', 'Visualisation de données', 'Structure de données', 'Volume', 'Quantité massive de données', 'Vélocité', 'Vitesse de génération de données', 'Système', 'Stocker gérer et récupérer des données', 'Base de données relationnelles', 'Relations entre les tables', 'Tirer', 'Données', 'Exploitables', 'Format prédéfini', 'Texte libre', 'Caractéristiques', 'Claire et standardisée', 'Passer', 'Interprétation des tendances', 'Data visualisation', 'Données brutes', 'Information claire', 'Processus', 'Visualisation', 'Objectif', 'Experts', 'Dataviz', 'Page layout', 'Interactive data visualization', 'Edward rolf tufte', 'Professor', 'Léonard de vinci des données', 'Théophile', 'Outil informatique', 'Ordinateur', 'Quantité de données phénoménales', \"Phase d'analyse\", 'Structure des données', 'Anomalies ou tendances', 'Utilise', 'Computer interface', 'Sujet à', 'Biais de perception', 'Les utilisateurs', 'Les données', 'La visualisation', 'La source', 'Traitement', 'Les [[dataviz]] produitent', \"Données d'[[input]]\", 'Tester', 'Parties prenantes', 'Hans rosling', 'Literary work', 'Sous-classe de', 'Agent', 'Art', 'Sélectionner visualisation', 'Mettre en évidence messages', 'Utilisateur final', \"Niveaux d'informations\", 'Visualisations', 'Métadonnées', 'Date', 'Données structurées', 'Outils comme sql', \"L'art de la dataviz\", 'Trucs en connaissances', 'Service communication', 'Instinct', 'Réalité polarisée', 'Série temporelle', 'Graphique en ligne', 'Comparaisons entre catégories', 'Diagramme à barre ou camembert', 'Examiner', 'Fournies', 'Identifier', 'Relations entre les données']\n",
      "Edges: [('Exactitude', 'Justes et cohérentes'), ('Complétude', 'Complet'), ('Nettoyage', 'Erreurs'), ('Normalisation', 'Formats'), ('Florence nightingale', 'Infirmière britannique'), ('Florence nightingale', \"Présentation visuelle de l'information\"), ('Dataviz project', 'Relation'), ('Dataviz project', 'Bibliothèque'), ('Dataviz project', 'Description'), ('Visualisation de données', 'Structure de données'), ('Volume', 'Quantité massive de données'), ('Vélocité', 'Vitesse de génération de données'), ('Système', 'Stocker gérer et récupérer des données'), ('Base de données relationnelles', 'Relations entre les tables'), ('Tirer', 'Données'), ('Données', 'Exploitables'), ('Données', 'Format prédéfini'), ('Données', 'Texte libre'), ('Données', 'Caractéristiques'), ('Données', 'Claire et standardisée'), ('Données', 'Processus'), ('Données', 'Utilisateur final'), ('Données', 'Service communication'), ('Passer', 'Interprétation des tendances'), ('Data visualisation', 'Données brutes'), ('Data visualisation', 'Information claire'), ('Visualisation', 'Objectif'), ('Visualisation', 'Experts'), ('Dataviz', 'Page layout'), ('Dataviz', 'Interactive data visualization'), ('Dataviz', 'Utilise'), ('Edward rolf tufte', 'Professor'), ('Edward rolf tufte', 'Léonard de vinci des données'), ('Théophile', 'Outil informatique'), ('Ordinateur', 'Quantité de données phénoménales'), (\"Phase d'analyse\", 'Structure des données'), (\"Phase d'analyse\", 'Anomalies ou tendances'), ('Utilise', 'Computer interface'), ('Sujet à', 'Biais de perception'), ('Biais de perception', 'Literary work'), ('Les utilisateurs', 'Les données'), ('Les utilisateurs', 'La visualisation'), ('Les données', 'La source'), ('Les données', 'Traitement'), ('Les [[dataviz]] produitent', \"Données d'[[input]]\"), ('Tester', 'Parties prenantes'), ('Hans rosling', 'Literary work'), ('Sous-classe de', 'Agent'), ('Art', 'Sélectionner visualisation'), ('Art', 'Mettre en évidence messages'), ('Utilisateur final', \"Niveaux d'informations\"), ('Utilisateur final', 'Visualisations'), ('Métadonnées', 'Date'), ('Données structurées', 'Outils comme sql'), (\"L'art de la dataviz\", 'Trucs en connaissances'), ('Instinct', 'Réalité polarisée'), ('Série temporelle', 'Graphique en ligne'), ('Comparaisons entre catégories', 'Diagramme à barre ou camembert'), ('Examiner', 'Fournies'), ('Identifier', 'Relations entre les données')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d6f30",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81374cd9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "330e38ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e323b",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "c0dd0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf2d82b40d24bc09f08e97191a76ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 8140ac08-3cb9-4e54-a6b5-1e8e8ce3c81d: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 8140ac08-3cb9-4e54-a6b5-1e8e8ce3c81d: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 8140ac08-3cb9-4e54-a6b5-1e8e8ce3c81d: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 8140ac08-3cb9-4e54-a6b5-1e8e8ce3c81d: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 8140ac08-3cb9-4e54-a6b5-1e8e8ce3c81d: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 8dfe6545-46a0-4a59-ac7d-2d5d45df7ed0: Quels critères pour dire que des données sont de qualité ?\n",
      "- Exactitude : les...\n",
      "> Querying with idx: 8dfe6545-46a0-4a59-ac7d-2d5d45df7ed0: Quels critères pour dire que des données sont de qualité ?\n",
      "- Exactitude : les...\n",
      "> Querying with idx: 8dfe6545-46a0-4a59-ac7d-2d5d45df7ed0: Quels critères pour dire que des données sont de qualité ?\n",
      "- Exactitude : les...\n",
      "> Querying with idx: 8dfe6545-46a0-4a59-ac7d-2d5d45df7ed0: Quels critères pour dire que des données sont de qualité ?\n",
      "- Exactitude : les...\n",
      "> Querying with idx: 8dfe6545-46a0-4a59-ac7d-2d5d45df7ed0: Quels critères pour dire que des données sont de qualité ?\n",
      "- Exactitude : les...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 896a6168-df9f-4f23-a0b7-c5133d54cfe1: ---\n",
      "pionnière de: \"[[dataviz]]\"\n",
      "---\n",
      "\n",
      "**Florence Nightingale**, née le 12 mai ...\n",
      "> Querying with idx: 896a6168-df9f-4f23-a0b7-c5133d54cfe1: ---\n",
      "pionnière de: \"[[dataviz]]\"\n",
      "---\n",
      "\n",
      "**Florence Nightingale**, née le 12 mai ...\n",
      "> Querying with idx: 896a6168-df9f-4f23-a0b7-c5133d54cfe1: ---\n",
      "pionnière de: \"[[dataviz]]\"\n",
      "---\n",
      "\n",
      "**Florence Nightingale**, née le 12 mai ...\n",
      "> Querying with idx: 896a6168-df9f-4f23-a0b7-c5133d54cfe1: ---\n",
      "pionnière de: \"[[dataviz]]\"\n",
      "---\n",
      "\n",
      "**Florence Nightingale**, née le 12 mai ...\n",
      "> Querying with idx: 896a6168-df9f-4f23-a0b7-c5133d54cfe1: ---\n",
      "pionnière de: \"[[dataviz]]\"\n",
      "---\n",
      "\n",
      "**Florence Nightingale**, née le 12 mai ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 269cd6f4-88ee-4bbb-896e-8191049f8b8a: > Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à l...\n",
      "> Querying with idx: 269cd6f4-88ee-4bbb-896e-8191049f8b8a: > Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à l...\n",
      "> Querying with idx: 269cd6f4-88ee-4bbb-896e-8191049f8b8a: > Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à l...\n",
      "> Querying with idx: 269cd6f4-88ee-4bbb-896e-8191049f8b8a: > Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à l...\n",
      "> Querying with idx: 269cd6f4-88ee-4bbb-896e-8191049f8b8a: > Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à l...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7a3c86ad-b7d5-441a-b0bc-ea02d304611a: Attention c'est un gros mot \n",
      "Les 3V \n",
      "- Volume : quantité massive de données\n",
      "-...\n",
      "> Querying with idx: 7a3c86ad-b7d5-441a-b0bc-ea02d304611a: Attention c'est un gros mot \n",
      "Les 3V \n",
      "- Volume : quantité massive de données\n",
      "-...\n",
      "> Querying with idx: 7a3c86ad-b7d5-441a-b0bc-ea02d304611a: Attention c'est un gros mot \n",
      "Les 3V \n",
      "- Volume : quantité massive de données\n",
      "-...\n",
      "> Querying with idx: 7a3c86ad-b7d5-441a-b0bc-ea02d304611a: Attention c'est un gros mot \n",
      "Les 3V \n",
      "- Volume : quantité massive de données\n",
      "-...\n",
      "> Querying with idx: 7a3c86ad-b7d5-441a-b0bc-ea02d304611a: Attention c'est un gros mot \n",
      "Les 3V \n",
      "- Volume : quantité massive de données\n",
      "-...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0e81bb91-2dba-4875-9f7a-610b66bb682b: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 0e81bb91-2dba-4875-9f7a-610b66bb682b: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 0e81bb91-2dba-4875-9f7a-610b66bb682b: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 0e81bb91-2dba-4875-9f7a-610b66bb682b: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 0e81bb91-2dba-4875-9f7a-610b66bb682b: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9b9e422b-f766-448c-9fe6-981298a285b0: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 9b9e422b-f766-448c-9fe6-981298a285b0: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 9b9e422b-f766-448c-9fe6-981298a285b0: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 9b9e422b-f766-448c-9fe6-981298a285b0: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 9b9e422b-f766-448c-9fe6-981298a285b0: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 8df54673-baf4-4746-a92c-78b65d486165: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 8df54673-baf4-4746-a92c-78b65d486165: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 8df54673-baf4-4746-a92c-78b65d486165: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 8df54673-baf4-4746-a92c-78b65d486165: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 8df54673-baf4-4746-a92c-78b65d486165: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: f41a8210-b9b7-44ba-b698-619875ff3c8c: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: f41a8210-b9b7-44ba-b698-619875ff3c8c: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: f41a8210-b9b7-44ba-b698-619875ff3c8c: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: f41a8210-b9b7-44ba-b698-619875ff3c8c: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: f41a8210-b9b7-44ba-b698-619875ff3c8c: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "graph_rag_retriever = graph_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(\n",
    "    \"Qui est-tu ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d1031a44-f06e-400f-beaa-2065beeee9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Je suis un système de questions-réponses conçu pour fournir des réponses précises et fiables en utilisant les informations disponibles.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e7541",
   "metadata": {},
   "source": [
    "## Load onto index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bb203e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "onto_storage_context = StorageContext.from_defaults(persist_dir=\"onto_graph\")\n",
    "# Load the PropertyGraphIndex from the storage context\n",
    "\n",
    "onto_index = load_index_from_storage(onto_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a182d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_index.property_graph_store.save_networkx_graph(\n",
    "    name=\"OntoGraph.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4dcae",
   "metadata": {},
   "source": [
    "### Set retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bee17732",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95920ba",
   "metadata": {},
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4c400086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cebe7661b84384b2681bb250f71377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "onto_rag_retriever = onto_index.as_retriever(\n",
    "    retriever_mode=\"hybrid\",  # or \"embedding\" or \"hybrid\"\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(\n",
    "    \"Qui est-tu ?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "123366e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Je suis un système de questions-réponses conçu pour fournir des réponses précises et fiables en utilisant les informations disponibles.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b65be-955e-44db-942e-27e235384f19",
   "metadata": {},
   "source": [
    "# Visualize knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "55ef03a2-2e7e-443d-865f-b6d991d16416",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = graph_index.get_networkx_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b9d58e14-0017-494f-98ec-ad8b30bf8c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in the knowledge graph: 60\n"
     ]
    }
   ],
   "source": [
    "# Count the number of nodes\n",
    "num_nodes = len(nx_graph.edges())\n",
    "\n",
    "print(f\"Number of nodes in the knowledge graph: {num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a113918c-f195-4c8c-b0f3-c85d7a6c5d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 94 nodes and 60 edges\n",
      "Nodes: ['Exactitude', 'Justes et cohérentes', 'Complétude', 'Complet', 'Nettoyage', 'Erreurs', 'Normalisation', 'Formats', 'Florence nightingale', 'Infirmière britannique', \"Présentation visuelle de l'information\", 'Dataviz project', 'Relation', 'Bibliothèque', 'Description', 'Visualisation de données', 'Structure de données', 'Volume', 'Quantité massive de données', 'Vélocité', 'Vitesse de génération de données', 'Système', 'Stocker gérer et récupérer des données', 'Base de données relationnelles', 'Relations entre les tables', 'Tirer', 'Données', 'Exploitables', 'Format prédéfini', 'Texte libre', 'Caractéristiques', 'Claire et standardisée', 'Passer', 'Interprétation des tendances', 'Data visualisation', 'Données brutes', 'Information claire', 'Processus', 'Visualisation', 'Objectif', 'Experts', 'Dataviz', 'Page layout', 'Interactive data visualization', 'Edward rolf tufte', 'Professor', 'Léonard de vinci des données', 'Théophile', 'Outil informatique', 'Ordinateur', 'Quantité de données phénoménales', \"Phase d'analyse\", 'Structure des données', 'Anomalies ou tendances', 'Utilise', 'Computer interface', 'Sujet à', 'Biais de perception', 'Les utilisateurs', 'Les données', 'La visualisation', 'La source', 'Traitement', 'Les [[dataviz]] produitent', \"Données d'[[input]]\", 'Tester', 'Parties prenantes', 'Hans rosling', 'Literary work', 'Sous-classe de', 'Agent', 'Art', 'Sélectionner visualisation', 'Mettre en évidence messages', 'Utilisateur final', \"Niveaux d'informations\", 'Visualisations', 'Métadonnées', 'Date', 'Données structurées', 'Outils comme sql', \"L'art de la dataviz\", 'Trucs en connaissances', 'Service communication', 'Instinct', 'Réalité polarisée', 'Série temporelle', 'Graphique en ligne', 'Comparaisons entre catégories', 'Diagramme à barre ou camembert', 'Examiner', 'Fournies', 'Identifier', 'Relations entre les données']\n",
      "Edges: [('Exactitude', 'Justes et cohérentes'), ('Complétude', 'Complet'), ('Nettoyage', 'Erreurs'), ('Normalisation', 'Formats'), ('Florence nightingale', 'Infirmière britannique'), ('Florence nightingale', \"Présentation visuelle de l'information\"), ('Dataviz project', 'Relation'), ('Dataviz project', 'Bibliothèque'), ('Dataviz project', 'Description'), ('Visualisation de données', 'Structure de données'), ('Volume', 'Quantité massive de données'), ('Vélocité', 'Vitesse de génération de données'), ('Système', 'Stocker gérer et récupérer des données'), ('Base de données relationnelles', 'Relations entre les tables'), ('Tirer', 'Données'), ('Données', 'Exploitables'), ('Données', 'Format prédéfini'), ('Données', 'Texte libre'), ('Données', 'Caractéristiques'), ('Données', 'Claire et standardisée'), ('Données', 'Processus'), ('Données', 'Utilisateur final'), ('Données', 'Service communication'), ('Passer', 'Interprétation des tendances'), ('Data visualisation', 'Données brutes'), ('Data visualisation', 'Information claire'), ('Visualisation', 'Objectif'), ('Visualisation', 'Experts'), ('Dataviz', 'Page layout'), ('Dataviz', 'Interactive data visualization'), ('Dataviz', 'Utilise'), ('Edward rolf tufte', 'Professor'), ('Edward rolf tufte', 'Léonard de vinci des données'), ('Théophile', 'Outil informatique'), ('Ordinateur', 'Quantité de données phénoménales'), (\"Phase d'analyse\", 'Structure des données'), (\"Phase d'analyse\", 'Anomalies ou tendances'), ('Utilise', 'Computer interface'), ('Sujet à', 'Biais de perception'), ('Biais de perception', 'Literary work'), ('Les utilisateurs', 'Les données'), ('Les utilisateurs', 'La visualisation'), ('Les données', 'La source'), ('Les données', 'Traitement'), ('Les [[dataviz]] produitent', \"Données d'[[input]]\"), ('Tester', 'Parties prenantes'), ('Hans rosling', 'Literary work'), ('Sous-classe de', 'Agent'), ('Art', 'Sélectionner visualisation'), ('Art', 'Mettre en évidence messages'), ('Utilisateur final', \"Niveaux d'informations\"), ('Utilisateur final', 'Visualisations'), ('Métadonnées', 'Date'), ('Données structurées', 'Outils comme sql'), (\"L'art de la dataviz\", 'Trucs en connaissances'), ('Instinct', 'Réalité polarisée'), ('Série temporelle', 'Graphique en ligne'), ('Comparaisons entre catégories', 'Diagramme à barre ou camembert'), ('Examiner', 'Fournies'), ('Identifier', 'Relations entre les données')]\n"
     ]
    }
   ],
   "source": [
    "g = graph_index.get_networkx_graph()\n",
    "print(g)\n",
    "print(\"Nodes:\", g.nodes())\n",
    "print(\"Edges:\", g.edges())\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "with open(\"knowledge_graph.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(net.generate_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab94fc0-2080-4869-94a0-b013dc0fbd9d",
   "metadata": {},
   "source": [
    "# (Simple) Query the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6c93bdbb-aaa4-4658-aecf-1cd7b5038ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cdea57ae1945fbbc7c782b8117c92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Qui est-tu ?\"\n",
    "query_engine = simple_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e2a871b4-70c8-45ed-a8b9-b2aaa8d15a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Je suis un système de questions-réponses conçu pour fournir des réponses précises et fiables en utilisant les informations disponibles. Mon objectif est d'aider à clarifier des sujets en fonction des données fournies.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099031c-b137-468f-b20c-9c6fab1c4eb1",
   "metadata": {},
   "source": [
    "# (Simple) Query the knowledge graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8948dd2b-acd4-4621-a2d1-b45034a21007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91369413c68747768787b451a147b3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 8140ac08-3cb9-4e54-a6b5-1e8e8ce3c81d: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 8140ac08-3cb9-4e54-a6b5-1e8e8ce3c81d: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 8140ac08-3cb9-4e54-a6b5-1e8e8ce3c81d: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 8140ac08-3cb9-4e54-a6b5-1e8e8ce3c81d: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "> Querying with idx: 8140ac08-3cb9-4e54-a6b5-1e8e8ce3c81d: Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 8dfe6545-46a0-4a59-ac7d-2d5d45df7ed0: Quels critères pour dire que des données sont de qualité ?\n",
      "- Exactitude : les...\n",
      "> Querying with idx: 8dfe6545-46a0-4a59-ac7d-2d5d45df7ed0: Quels critères pour dire que des données sont de qualité ?\n",
      "- Exactitude : les...\n",
      "> Querying with idx: 8dfe6545-46a0-4a59-ac7d-2d5d45df7ed0: Quels critères pour dire que des données sont de qualité ?\n",
      "- Exactitude : les...\n",
      "> Querying with idx: 8dfe6545-46a0-4a59-ac7d-2d5d45df7ed0: Quels critères pour dire que des données sont de qualité ?\n",
      "- Exactitude : les...\n",
      "> Querying with idx: 8dfe6545-46a0-4a59-ac7d-2d5d45df7ed0: Quels critères pour dire que des données sont de qualité ?\n",
      "- Exactitude : les...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 896a6168-df9f-4f23-a0b7-c5133d54cfe1: ---\n",
      "pionnière de: \"[[dataviz]]\"\n",
      "---\n",
      "\n",
      "**Florence Nightingale**, née le 12 mai ...\n",
      "> Querying with idx: 896a6168-df9f-4f23-a0b7-c5133d54cfe1: ---\n",
      "pionnière de: \"[[dataviz]]\"\n",
      "---\n",
      "\n",
      "**Florence Nightingale**, née le 12 mai ...\n",
      "> Querying with idx: 896a6168-df9f-4f23-a0b7-c5133d54cfe1: ---\n",
      "pionnière de: \"[[dataviz]]\"\n",
      "---\n",
      "\n",
      "**Florence Nightingale**, née le 12 mai ...\n",
      "> Querying with idx: 896a6168-df9f-4f23-a0b7-c5133d54cfe1: ---\n",
      "pionnière de: \"[[dataviz]]\"\n",
      "---\n",
      "\n",
      "**Florence Nightingale**, née le 12 mai ...\n",
      "> Querying with idx: 896a6168-df9f-4f23-a0b7-c5133d54cfe1: ---\n",
      "pionnière de: \"[[dataviz]]\"\n",
      "---\n",
      "\n",
      "**Florence Nightingale**, née le 12 mai ...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 269cd6f4-88ee-4bbb-896e-8191049f8b8a: > Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à l...\n",
      "> Querying with idx: 269cd6f4-88ee-4bbb-896e-8191049f8b8a: > Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à l...\n",
      "> Querying with idx: 269cd6f4-88ee-4bbb-896e-8191049f8b8a: > Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à l...\n",
      "> Querying with idx: 269cd6f4-88ee-4bbb-896e-8191049f8b8a: > Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à l...\n",
      "> Querying with idx: 269cd6f4-88ee-4bbb-896e-8191049f8b8a: > Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à l...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 7a3c86ad-b7d5-441a-b0bc-ea02d304611a: Attention c'est un gros mot \n",
      "Les 3V \n",
      "- Volume : quantité massive de données\n",
      "-...\n",
      "> Querying with idx: 7a3c86ad-b7d5-441a-b0bc-ea02d304611a: Attention c'est un gros mot \n",
      "Les 3V \n",
      "- Volume : quantité massive de données\n",
      "-...\n",
      "> Querying with idx: 7a3c86ad-b7d5-441a-b0bc-ea02d304611a: Attention c'est un gros mot \n",
      "Les 3V \n",
      "- Volume : quantité massive de données\n",
      "-...\n",
      "> Querying with idx: 7a3c86ad-b7d5-441a-b0bc-ea02d304611a: Attention c'est un gros mot \n",
      "Les 3V \n",
      "- Volume : quantité massive de données\n",
      "-...\n",
      "> Querying with idx: 7a3c86ad-b7d5-441a-b0bc-ea02d304611a: Attention c'est un gros mot \n",
      "Les 3V \n",
      "- Volume : quantité massive de données\n",
      "-...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 0e81bb91-2dba-4875-9f7a-610b66bb682b: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 0e81bb91-2dba-4875-9f7a-610b66bb682b: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 0e81bb91-2dba-4875-9f7a-610b66bb682b: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 0e81bb91-2dba-4875-9f7a-610b66bb682b: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "> Querying with idx: 0e81bb91-2dba-4875-9f7a-610b66bb682b: Données sur les [[données]]\n",
      "Permet de décrire les caractéristiques ou le cont...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 9b9e422b-f766-448c-9fe6-981298a285b0: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 9b9e422b-f766-448c-9fe6-981298a285b0: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 9b9e422b-f766-448c-9fe6-981298a285b0: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 9b9e422b-f766-448c-9fe6-981298a285b0: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "> Querying with idx: 9b9e422b-f766-448c-9fe6-981298a285b0: [[données]] organisées de manière claire et standardisée\n",
      "On les retrouve le p...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 8df54673-baf4-4746-a92c-78b65d486165: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 8df54673-baf4-4746-a92c-78b65d486165: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 8df54673-baf4-4746-a92c-78b65d486165: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 8df54673-baf4-4746-a92c-78b65d486165: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "> Querying with idx: 8df54673-baf4-4746-a92c-78b65d486165: Processus de préparation des [[données]] pour les rendre exploitables\n",
      "- Suppr...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: f41a8210-b9b7-44ba-b698-619875ff3c8c: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: f41a8210-b9b7-44ba-b698-619875ff3c8c: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: f41a8210-b9b7-44ba-b698-619875ff3c8c: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: f41a8210-b9b7-44ba-b698-619875ff3c8c: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "> Querying with idx: f41a8210-b9b7-44ba-b698-619875ff3c8c: Ajout d'éléments dynamiques pour permettre aux [[utilisateur final]]s d'explo...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Qui est-tu ?\"\n",
    "graph_query_engine = graph_index.as_query_engine(\n",
    " include_text=True,\n",
    " response_mode=\"tree_summarize\",\n",
    " embedding_mode=\"hybrid\",\n",
    " similarity_top_k=8,\n",
    ")\n",
    "\n",
    "response = graph_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ff5382fd-1fc8-4faf-9356-c9bb3e478db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Je suis un système de questions-réponses conçu pour fournir des réponses précises et fiables en utilisant les informations disponibles.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef119d0",
   "metadata": {},
   "source": [
    "# (Simple) Query the onto graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a8db6420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4487b5a77e7401d9423f00df4053d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"Qui est-tu ?\"\n",
    "onto_query_engine = onto_index.as_query_engine(\n",
    " include_text=True,\n",
    " similarity_top_k=2,\n",
    ")\n",
    "\n",
    "response = onto_query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "adcd4265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>Je suis un système de questions-réponses conçu pour fournir des réponses précises en utilisant les informations disponibles.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582274ba",
   "metadata": {},
   "source": [
    "## (Node retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "16db2a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ff6070fbd54f8d95cf457d98183a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "dataviz -> INVOLVES -> interaction entre l'homme et la donnée\n",
      "\n",
      "Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas de trucs qu'on sait pas trop comment définir en des connaissances et des idées et leur donner une application dans la vie courante.\n",
      "\n",
      "**Exemple :** Le service communication d'une entreprise analyse les données relatives à l'envoi d'une newsletter pour comprendre ce qui a mieux ou moins bien marché. Ils utilisent des outils qui mettent en forment les données et en produisent des évaluations, parfois même des interprétations.\n",
      "\n",
      "Pour comprendre les données, on cherche à analyser les [[Inférence]]s et trouver des relation dans notre tas d'informations.\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "traitement du langage naturel -> EXAMPLE_OF -> outils spécialisés\n",
      "contenu en flux -> ARE -> données\n",
      "réseaux sociaux -> HOST -> contenu en flux\n",
      "\n",
      "Données qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir du texte libre, des images, des vidéos ou des documents. \n",
      "Par exemple : des mails, des enregistrements audio ou du contenu en flux sur les réseaux sociaux. \n",
      "Pour les interpréter il faut des outils spécialisés comme le traitement du langage naturel ou la reconnaissance d'image pour être analysées.****\n",
      "Here are some facts extracted from the provided text:\n",
      "\n",
      "bonnes pratiques -> APPLIED_TO -> réceptionner, gérer et exploiter des données\n",
      "\n",
      "> Perso, ce qui m'emmerde au quotidien c'est qu'on me balance des données à la gueule et on me dit \"allez, fais moi une synthèse graphique\" et je suis paumé\n",
      "\n",
      "\n",
      "\n",
      "Que faire quand on se retrouve face à une montagne de [[données]]\n",
      "Quels sont les [[outils]] à disposition ? \n",
      "Quelles sont les bonnes pratiques pour réceptionner, gérer et exploiter des données ? \n",
      "\n",
      "\n",
      "Quelle est la part d'adaptation que l'on peut offrir quand on se retrouve face à quelque chose d'aussi rigoureux que la manipulation de données ?\n",
      "\n",
      "Pour moi (théophile) : la question de la donnée est intrinsèquement liée à la question de l'outil informatique puisque c'est comme ça qu'on la manipule aujourd'hui. Mais il y a aussi quelque chose de vertigineux dans le fait que l'outil avec lequel on manipule nos données (un ordinateur) manipule lui même une quantité de données phénoménales.\n",
      "\n",
      "La donnée des uns sera-t-elle la donnée des autres ? \n",
      "Comment assurer une transmission de la donnée ? \n",
      "Est-ce tout le point de la dataviz ? \n",
      "\n",
      "Dans la question de la dataviz et de son but il y a la question de l'interaction entre l'homme et la donnée\n"
     ]
    }
   ],
   "source": [
    "retriever = onto_index.as_retriever(\n",
    "    include_text=True,  # include source text, default True\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(\"Qui est-tu ?\")\n",
    "\n",
    "\n",
    "for node in nodes:\n",
    "    print(node.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a895520-d196-476f-b569-69a67484c120",
   "metadata": {},
   "source": [
    "# Have a real chat with your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3764d-a084-4f36-9d8c-3613aa9fd835",
   "metadata": {},
   "source": [
    "## Set up the engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e55a2-a9a9-4c4e-89a4-c4dfba55ebe4",
   "metadata": {},
   "source": [
    "### Vector engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1581c90c-cf5a-40d3-81b0-086238068f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "vector_chat_engine = simple_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \" \"\n",
    "        \" \"\n",
    "        \".\"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315a1c22-111b-4793-8a3d-bd3eae7e3ec7",
   "metadata": {},
   "source": [
    "### Graph engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "98b73cc2-0588-4b96-9aa2-1dfaf4cadb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897ec22",
   "metadata": {},
   "source": [
    "### Onto engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "54d04e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onto_chat_engine = onto_index.query_engine(\n",
    "#    chat_mode=\"condense_plus_context\",\n",
    "#    llm=llm\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e0a08-f6ff-4ee6-a165-9b9fd90621fa",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "12804e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_chat_engine.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "709a37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "graph_chat_engine = graph_index.as_chat_engine(\n",
    "    chat_mode=\"condense_plus_context\",\n",
    "    memory=memory,\n",
    "    llm=llm,\n",
    "    context_prompt=(\n",
    "        \"Tu dois générer des générer des méthodologies de dataviz centrées autour de la découverte de lignes de force entre idées\"\n",
    "        \" \"\n",
    "        \" \"\n",
    "    ),\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "da3e3ebf-18dc-4bdc-87dc-58d0227e9c18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: D'après ta base de connaissance et ta vision du monde, dans le cadre d'une analyse de l'impact des tendances économiques sur les comportements de consommation, créer un diagramme de corrélation entre les idées principales telles que la croissance économique, l'inflation, et les choix des consommateurs, pour visualiser les relations fortes et faibles entre ces variables.\n",
      "Condensed question: D'après ta base de connaissance et ta vision du monde, dans le cadre d'une analyse de l'impact des tendances économiques sur les comportements de consommation, créer un diagramme de corrélation entre les idées principales telles que la croissance économique, l'inflation, et les choix des consommateurs, pour visualiser les relations fortes et faibles entre ces variables.\n",
      "Condensed question: D'après ta base de connaissance et ta vision du monde, dans le cadre d'une analyse de l'impact des tendances économiques sur les comportements de consommation, créer un diagramme de corrélation entre les idées principales telles que la croissance économique, l'inflation, et les choix des consommateurs, pour visualiser les relations fortes et faibles entre ces variables.\n",
      "Condensed question: D'après ta base de connaissance et ta vision du monde, dans le cadre d'une analyse de l'impact des tendances économiques sur les comportements de consommation, créer un diagramme de corrélation entre les idées principales telles que la croissance économique, l'inflation, et les choix des consommateurs, pour visualiser les relations fortes et faibles entre ces variables.\n",
      "Condensed question: D'après ta base de connaissance et ta vision du monde, dans le cadre d'une analyse de l'impact des tendances économiques sur les comportements de consommation, créer un diagramme de corrélation entre les idées principales telles que la croissance économique, l'inflation, et les choix des consommateurs, pour visualiser les relations fortes et faibles entre ces variables.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9234013b744bf3bd8960ce3b73d18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 13c12931-e4e2-4bc8-b819-40e2ffae0d7f: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 13c12931-e4e2-4bc8-b819-40e2ffae0d7f: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 13c12931-e4e2-4bc8-b819-40e2ffae0d7f: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 13c12931-e4e2-4bc8-b819-40e2ffae0d7f: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "> Querying with idx: 13c12931-e4e2-4bc8-b819-40e2ffae0d7f: En fonction de la nature des données, on ne choisit pas les mêmes types de re...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: be5f0df9-4609-4a4a-b429-e3529e134898: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: be5f0df9-4609-4a4a-b429-e3529e134898: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: be5f0df9-4609-4a4a-b429-e3529e134898: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: be5f0df9-4609-4a4a-b429-e3529e134898: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n",
      "> Querying with idx: be5f0df9-4609-4a4a-b429-e3529e134898: ---\n",
      "partie de:\n",
      "  - \"[[Dataviz Project]]\"\n",
      "  - \"[[dataviz]]\"\n",
      "---\n",
      "A chaque visua...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"D'après ta base de connaissance et ta vision du monde, dans le cadre d'une analyse de l'impact des tendances économiques sur les comportements de consommation, créer un diagramme de corrélation entre les idées principales telles que la croissance économique, l'inflation, et les choix des consommateurs, pour visualiser les relations fortes et faibles entre ces variables.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "91ebf21f-1990-4a4d-9c9a-868872f03042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Pour créer un diagramme de corrélation qui visualise les relations entre la croissance économique, l'inflation, et les choix des consommateurs, nous pouvons suivre une méthodologie structurée. Voici les étapes pour réaliser cette datavisualisation :\n",
      "\n",
      "### Étape 1 : Collecte de données\n",
      "- **Sources de données** : Rassemblez des données historiques sur la croissance économique (PIB), l'inflation (IPC), et les comportements de consommation (dépenses des ménages, préférences d'achat, etc.) à partir de sources fiables comme les banques centrales, les instituts de statistiques nationaux, ou des bases de données économiques internationales.\n",
      "- **Période d'analyse** : Définissez une période d'analyse pertinente, par exemple, les 10 dernières années, pour observer les tendances à long terme.\n",
      "\n",
      "### Étape 2 : Préparation des données\n",
      "- **Nettoyage des données** : Assurez-vous que les données sont propres, sans valeurs manquantes ou aberrantes.\n",
      "- **Normalisation** : Si nécessaire, normalisez les données pour les rendre comparables, surtout si elles sont exprimées dans des unités différentes.\n",
      "\n",
      "### Étape 3 : Analyse statistique\n",
      "- **Calcul des corrélations** : Utilisez des méthodes statistiques pour calculer les coefficients de corrélation entre les variables. Le coefficient de corrélation de Pearson est souvent utilisé pour mesurer la force et la direction de la relation linéaire entre deux variables.\n",
      "- **Interprétation des coefficients** : \n",
      "  - Un coefficient proche de +1 indique une forte corrélation positive.\n",
      "  - Un coefficient proche de -1 indique une forte corrélation négative.\n",
      "  - Un coefficient proche de 0 indique une faible ou aucune corrélation.\n",
      "\n",
      "### Étape 4 : Visualisation\n",
      "- **Choix de l'outil** : Utilisez un logiciel de visualisation de données comme Tableau, Power BI, ou Python (matplotlib, seaborn) pour créer le diagramme.\n",
      "- **Création du diagramme de corrélation** :\n",
      "  - **Matrice de corrélation** : Représentez les coefficients de corrélation sous forme de matrice, où chaque cellule montre la corrélation entre deux variables.\n",
      "  - **Heatmap** : Utilisez une heatmap pour visualiser la matrice de corrélation. Les couleurs peuvent indiquer la force et la direction des corrélations (par exemple, du bleu pour les corrélations négatives au rouge pour les corrélations positives).\n",
      "  - **Annotations** : Ajoutez des annotations pour indiquer les valeurs exactes des coefficients de corrélation.\n",
      "\n",
      "### Étape 5 : Interprétation et communication\n",
      "- **Identifier les lignes de force** : Analysez la heatmap pour identifier les relations fortes entre les variables. Par exemple, une forte corrélation positive entre la croissance économique et les dépenses des ménages pourrait indiquer que les consommateurs dépensent plus lorsque l'économie est en croissance.\n",
      "- **Rapport et recommandations** : Rédigez un rapport qui interprète les résultats et propose des recommandations basées sur les corrélations observées. Par exemple, si l'inflation a une forte corrélation négative avec les choix de consommation, cela pourrait suggérer que les consommateurs réduisent leurs dépenses en période d'inflation élevée.\n",
      "\n",
      "En suivant cette méthodologie, vous pouvez créer un diagramme de corrélation efficace qui met en lumière les relations entre les tendances économiques et les comportements de consommation, facilitant ainsi la prise de décision stratégique."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5a056a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6660a81e-ad67-4d44-a86d-0ad7b77f626e",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_modele = \"\"\" \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9c0e462e-d3ee-463a-8d49-f09dc2396b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.chat_engine.condense_plus_context:Condensed question: Dans le cadre d'une recherche sur l'innovation technologique, comment concevoir un graphique de type réseau où les nœuds représentent des idées telles que la R&D, la disruption technologique, et l'adoption par les consommateurs, et où les arêtes indiquent les connexions les plus solides et significatives, en imitant le style d'écriture de la section modèle ?\n",
      "Condensed question: Dans le cadre d'une recherche sur l'innovation technologique, comment concevoir un graphique de type réseau où les nœuds représentent des idées telles que la R&D, la disruption technologique, et l'adoption par les consommateurs, et où les arêtes indiquent les connexions les plus solides et significatives, en imitant le style d'écriture de la section modèle ?\n",
      "Condensed question: Dans le cadre d'une recherche sur l'innovation technologique, comment concevoir un graphique de type réseau où les nœuds représentent des idées telles que la R&D, la disruption technologique, et l'adoption par les consommateurs, et où les arêtes indiquent les connexions les plus solides et significatives, en imitant le style d'écriture de la section modèle ?\n",
      "Condensed question: Dans le cadre d'une recherche sur l'innovation technologique, comment concevoir un graphique de type réseau où les nœuds représentent des idées telles que la R&D, la disruption technologique, et l'adoption par les consommateurs, et où les arêtes indiquent les connexions les plus solides et significatives, en imitant le style d'écriture de la section modèle ?\n",
      "Condensed question: Dans le cadre d'une recherche sur l'innovation technologique, comment concevoir un graphique de type réseau où les nœuds représentent des idées telles que la R&D, la disruption technologique, et l'adoption par les consommateurs, et où les arêtes indiquent les connexions les plus solides et significatives, en imitant le style d'écriture de la section modèle ?\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf994e53c05f4adc9cb365660cea38f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 2bae5942-7afe-48d2-a354-ae38118d8fea: Manière dont les utilisateurs interprètent les données au travers de la visua...\n",
      "> Querying with idx: 2bae5942-7afe-48d2-a354-ae38118d8fea: Manière dont les utilisateurs interprètent les données au travers de la visua...\n",
      "> Querying with idx: 2bae5942-7afe-48d2-a354-ae38118d8fea: Manière dont les utilisateurs interprètent les données au travers de la visua...\n",
      "> Querying with idx: 2bae5942-7afe-48d2-a354-ae38118d8fea: Manière dont les utilisateurs interprètent les données au travers de la visua...\n",
      "> Querying with idx: 2bae5942-7afe-48d2-a354-ae38118d8fea: Manière dont les utilisateurs interprètent les données au travers de la visua...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n",
      "> Querying with idx: 3a4d198b-ec6a-4de4-988b-a1bf59971291: Tout n'est que données \n",
      "L'art de la [[dataviz]] c'est de transformer un tas d...\n"
     ]
    }
   ],
   "source": [
    "response_stream = graph_chat_engine.stream_chat(\"\"\"D'après ta base de connaissance et ta vision du monde, dans le cadre d'une recherche sur l'innovation technologique, concevoir un graphique de type réseau où les nœuds représentent des idées comme la R&D, la disruption technologique, et l'adoption par les consommateurs, et les arêtes indiquent les connexions les plus solides et significatives. Imite le style d'écriture de la {section_modele}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c86075ee-12c8-4b97-8b51-0c717fc4b1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Pour concevoir un graphique de type réseau dans le cadre d'une recherche sur l'innovation technologique, nous allons suivre une méthodologie qui met en avant les connexions significatives entre des idées clés telles que la R&D, la disruption technologique, et l'adoption par les consommateurs. Voici comment procéder :\n",
      "\n",
      "### Étape 1 : Identification des idées clés\n",
      "- **Nœuds principaux** : Définissez les idées principales qui seront représentées comme des nœuds dans le réseau. Dans ce cas, les nœuds incluront la Recherche et Développement (R&D), la disruption technologique, l'adoption par les consommateurs, le financement de l'innovation, et la réglementation.\n",
      "- **Sous-idées** : Identifiez des sous-idées ou concepts connexes qui peuvent enrichir le réseau, comme les partenariats stratégiques, les brevets, et les tendances du marché.\n",
      "\n",
      "### Étape 2 : Collecte et analyse des données\n",
      "- **Sources de données** : Rassemblez des données qualitatives et quantitatives à partir de publications académiques, rapports industriels, et bases de données sur l'innovation.\n",
      "- **Analyse des connexions** : Utilisez des méthodes d'analyse de contenu pour identifier les connexions et influences entre les idées. Par exemple, examinez comment la R&D influence la disruption technologique ou comment l'adoption par les consommateurs est affectée par la réglementation.\n",
      "\n",
      "### Étape 3 : Construction du réseau\n",
      "- **Création des nœuds** : Chaque idée principale et sous-idée est représentée par un nœud dans le graphique.\n",
      "- **Définition des arêtes** : Les arêtes représentent les connexions entre les nœuds. La force et la signification des connexions peuvent être déterminées par des critères tels que la fréquence des co-occurrences dans les données ou l'importance stratégique.\n",
      "\n",
      "### Étape 4 : Visualisation\n",
      "- **Choix de l'outil** : Utilisez un logiciel de visualisation de réseaux comme Gephi, Cytoscape, ou des bibliothèques Python comme NetworkX pour créer le graphique.\n",
      "- **Style du graphique** :\n",
      "  - **Taille des nœuds** : Ajustez la taille des nœuds en fonction de leur centralité ou importance dans le réseau.\n",
      "  - **Épaisseur des arêtes** : Variez l'épaisseur des arêtes pour indiquer la force des connexions. Les arêtes plus épaisses représentent des connexions plus solides.\n",
      "  - **Couleurs** : Utilisez des couleurs pour différencier les catégories d'idées ou pour indiquer le type de relation (par exemple, influence positive ou négative).\n",
      "\n",
      "### Étape 5 : Interprétation et communication\n",
      "- **Analyse des lignes de force** : Identifiez les lignes de force dans le réseau, telles que les connexions critiques entre la R&D et la disruption technologique, ou entre l'adoption par les consommateurs et les tendances du marché.\n",
      "- **Rapport et recommandations** : Préparez un rapport qui interprète le réseau, met en évidence les connexions clés, et propose des recommandations pour stimuler l'innovation technologique. Par exemple, renforcer les investissements en R&D pourrait accélérer la disruption technologique.\n",
      "\n",
      "En suivant cette méthodologie, vous pouvez créer un graphique de type réseau qui illustre efficacement les relations complexes entre les idées clés de l'innovation technologique, facilitant ainsi une compréhension approfondie des dynamiques en jeu."
     ]
    }
   ],
   "source": [
    "generate = response_stream.print_response_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ffb78d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>None</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{generate}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74a302-bb28-4bf8-9103-1f62750a5fc0",
   "metadata": {},
   "source": [
    "## Sum-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d81f7480-9d62-4952-948e-19e089d9da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = memory.get_all()\n",
    "\n",
    "# Assuming chat_history is available and contains your messages\n",
    "assistant_messages = [\n",
    "    message.content \n",
    "    for message in chat_history \n",
    "    if message.role == MessageRole.ASSISTANT  # Compare with the enum directly\n",
    "]\n",
    "\n",
    "\n",
    "output_filename = r\"/Users/arthursarazin/Documents/coreandgraphs/graphandvisualize/output.md\"\n",
    "# Write to a Markdown file\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    for msg in assistant_messages:\n",
    "        f.write(msg + \"\\n\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
