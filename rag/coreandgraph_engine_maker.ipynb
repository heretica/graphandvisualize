{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "614fc4e2-0e04-49b0-bf7c-05efee48933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.readers.obsidian import ObsidianReader\n",
    "import openai\n",
    "from llama_index.core.memory.chat_memory_buffer import MessageRole\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex, VectorStoreIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import Document, PropertyGraphIndex\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "import logging\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    SimpleLLMPathExtractor,\n",
    "    SchemaLLMPathExtractor,\n",
    "    DynamicLLMPathExtractor,\n",
    ")\n",
    "import yaml\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5e9f925-0bd9-406c-a41d-8be268260b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    load_indices_from_storage,\n",
    "    load_graph_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8291822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17dd9f9d-7e21-49ef-9a01-d8b0dd7fdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc2e828-7a94-463f-89b0-2d75521319a7",
   "metadata": {},
   "source": [
    "# Build a simple directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "280f6ae9-b082-4a6d-8705-12849fb1a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_glossary = SimpleDirectoryReader(\n",
    "    r\"/Users/arthursarazin/Documents/coreandgraphs/graphandvisualize/graph\"\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ecd2f3-059f-4cd8-b0ed-97e95ee5075e",
   "metadata": {},
   "source": [
    "# Upload Obsidian vault files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d00bb4",
   "metadata": {},
   "source": [
    "#### Using Obsidian reader from LLama Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d414a6d-46da-43dd-ad82-44f404c86ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#locate obsidian files that make your graph\n",
    "filepath = r\"/Users/arthursarazin/Documents/coreandgraphs/graphandvisualize/graph\"\n",
    "\n",
    "#load the graph files \n",
    "graph_files = ObsidianReader(filepath).load_data()\n",
    "print(list(graph_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4066792",
   "metadata": {},
   "source": [
    "# Using manual code to create specific ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16f92a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les métadonnées YAML et le titre d'un fichier Markdown\n",
    "def extract_metadata_and_title(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        # Recherchez la section YAML (entre `---` au début et à la fin)\n",
    "        if content.startswith(\"---\"):\n",
    "            try:\n",
    "                yaml_block = content.split(\"---\", 2)[1]\n",
    "                metadata = yaml.safe_load(yaml_block)\n",
    "                return os.path.basename(file_path).replace(\".md\", \"\"), metadata\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de l'extraction des métadonnées de {file_path}: {e}\")\n",
    "                return None, None\n",
    "        return os.path.basename(file_path).replace(\".md\", \"\"), None\n",
    "\n",
    "# Parcourir les fichiers Obsidian et créer des entités et relations\n",
    "def process_obsidian_notes(directory):\n",
    "    entities = []\n",
    "    relations = []\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".md\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                title, metadata = extract_metadata_and_title(file_path)\n",
    "                if title:\n",
    "                    # Ajouter l'entité basée sur le titre\n",
    "                    entities.append({\"name\": title})\n",
    "                    \n",
    "                    # Ajouter les relations basées sur les propriétés YAML\n",
    "                    if metadata:\n",
    "                        for key, value in metadata.items():\n",
    "                            relations.append({\n",
    "                                \"type\": key,  # Nom de la propriété comme relation\n",
    "                                \"source\": title,  # Titre du fichier comme entité source\n",
    "                                \"target\": value,  # Valeur de la propriété comme entité cible\n",
    "                            })\n",
    "    return entities, relations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95381307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation\n",
    "obsidian_dir = r\"C:\\Users\\asarazin\\OneDrive - Veltys Max\\Documents\\documente-marcel\\graph\"\n",
    "entities, relations = process_obsidian_notes(obsidian_dir)\n",
    "\n",
    "print(relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5efb9f-d02f-490e-966c-f490b5e9db3e",
   "metadata": {},
   "source": [
    "# Set LLM (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b597ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Charge les variables depuis le fichier .env\n",
    "api_key = os.getenv(\"OPENAI_API_KEY_UP\")\n",
    "# Modifier ou ajouter une variable d'environnement\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a30f2c04-d01b-47ce-a532-c6c8fb4ee42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-4o\", max_tokens=3000)\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a010330-bc6a-4e1c-8605-16afe8200585",
   "metadata": {},
   "source": [
    "# Set local LLM for embeddings ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6be1f9-b33d-400a-a471-eeeeb35c0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "#Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e871d-dbf8-4cb1-897d-bdaef21b170d",
   "metadata": {},
   "source": [
    "# Set LLM for chat  (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5843a4c5-e11f-4c32-b446-2aec529a5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = Ollama(model=\"tinyllama\", request_timeout=120.0)\n",
    "#Settings.llm = llm\n",
    "#Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c5460a-bb6d-4839-92db-1180e146af06",
   "metadata": {},
   "source": [
    "# Test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e0de1-14c5-4b4b-9e40-ebbdae50b263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a data governance consultant\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What's your favorite data tool ?\"),\n",
    "]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee83593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate vector store\n",
    "simple_glossary = SimpleDirectoryReader(\n",
    "    r\"/Users/arthursarazin/Documents/coreandgraphs/graphandvisualize/graph\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b83af3-ff18-40f0-8469-5c8b2a75b5dd",
   "metadata": {},
   "source": [
    "# Instantiate graph store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e12d5f9c-03ea-4af6-a3ad-c1764d08e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store = SimpleGraphStore()\n",
    "graph_storage_context = StorageContext.from_defaults(graph_store=graph_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f102bb",
   "metadata": {},
   "source": [
    "# Instantiate ontology store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a66387e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_store = SimpleGraphStore()\n",
    "onto_storage_context = StorageContext.from_defaults(graph_store=onto_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94eacca-42e3-4140-a620-c199f3578e6e",
   "metadata": {},
   "source": [
    "# Construct Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a821e-abd8-4cb4-b2dc-98163aa332df",
   "metadata": {},
   "source": [
    "## Construct Vector Store Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fee7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents = simple_glossary.load_data(),\n",
    "    show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c8c116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index to disk\n",
    "vector_index.set_index_id(\"vector_index\")\n",
    "vector_index.storage_context.persist(\"vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6061a476-f5cc-4805-ad25-6e1533e787e5",
   "metadata": {},
   "source": [
    "## Construct knowledge graph index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "250b454a-f598-4749-8847-f59fa3a36a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(doc):\n",
    "    # This function will be called for each document\n",
    "    print(f\"Processing document: {doc.doc_id}\")\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca242f4-8ce0-4599-a888-eccc840b1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your graph files loaded\n",
    "print(f\"Starting to process {len(graph_files)} documents...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73397fd8-2bb8-41c3-ae12-f64621c9fa54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wrap your document processing in a progress bar\n",
    "graph_index = KnowledgeGraphIndex.from_documents(\n",
    "        documents=[process_document(doc) for doc in graph_files],  # process one document at a time\n",
    "        max_triplets_per_chunk=2,\n",
    "        storage_context=graph_storage_context,\n",
    "        include_embeddings=True,\n",
    "    show_progress=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf91f91-dfe7-4034-8719-54b10a1d1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e2e5de7-68d1-4b89-b1c2-e703f31419d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_index.set_index_id(\"graph_index\")\n",
    "graph_index.storage_context.persist(\"knowledge_graph\")\n",
    "graph_storage_context.persist(persist_dir=\"knowledge_graph\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48545d",
   "metadata": {},
   "source": [
    "## Construct knowledge with ontology as assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64c7bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_store = SimpleGraphStore()\n",
    "onto_storage_context = StorageContext.from_defaults(graph_store=onto_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76ed084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurer DynamicLLMPathExtractor avec les entités et relations extraites\n",
    "kg_extractor = DynamicLLMPathExtractor(\n",
    "    llm=llm,\n",
    "    max_triplets_per_chunk=20,\n",
    "    num_workers=4,\n",
    "    allowed_entity_types=None,  # Si vous ne limitez pas les types d'entités\n",
    "    allowed_relation_types=None,  # Si vous ne limitez pas les types de relations\n",
    "    allowed_entity_props=None,\n",
    "    allowed_relation_props=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0225a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résumé des entités et relations extraites\n",
    "print(\"Entités :\")\n",
    "for entity in entities:\n",
    "    print(entity)\n",
    "\n",
    "print(\"\\nRelations :\")\n",
    "for relation in relations:\n",
    "    print(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e813096",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_index = PropertyGraphIndex.from_documents(\n",
    "    documents=[process_document(doc) for doc in graph_files],\n",
    "    llm=llm,\n",
    "    storage_context=onto_storage_context,\n",
    "    embed_kg_nodes=True,\n",
    "    kg_extractors=[kg_extractor],\n",
    "    show_progress=True,\n",
    "    graph_store=onto_store \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba268ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(onto_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7314a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index to disk\n",
    "onto_index.set_index_id(\"onto_index\")\n",
    "onto_index.storage_context.persist(\"onto_graph\")\n",
    "onto_storage_context.persist(persist_dir=\"onto_graph\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
