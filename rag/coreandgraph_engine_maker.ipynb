{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "614fc4e2-0e04-49b0-bf7c-05efee48933f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthursarazin/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.obsidian import ObsidianReader\n",
    "import openai\n",
    "from llama_index.core.memory.chat_memory_buffer import MessageRole\n",
    "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex, VectorStoreIndex\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import Document, PropertyGraphIndex\n",
    "from llama_index.core.storage.index_store import SimpleIndexStore\n",
    "from llama_index.core.vector_stores import SimpleVectorStore\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import os\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "import logging\n",
    "import sys\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "from llama_index.core.indices.property_graph import (\n",
    "    SimpleLLMPathExtractor,\n",
    "    SchemaLLMPathExtractor,\n",
    "    DynamicLLMPathExtractor,\n",
    ")\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e9f925-0bd9-406c-a41d-8be268260b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    load_index_from_storage,\n",
    "    load_indices_from_storage,\n",
    "    load_graph_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8291822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17dd9f9d-7e21-49ef-9a01-d8b0dd7fdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc2e828-7a94-463f-89b0-2d75521319a7",
   "metadata": {},
   "source": [
    "# Build a simple directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280f6ae9-b082-4a6d-8705-12849fb1a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_glossary = SimpleDirectoryReader(\n",
    "    r\"/Users/arthursarazin/Documents/coreandgraphs/graphandvisualize/graph\"\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ecd2f3-059f-4cd8-b0ed-97e95ee5075e",
   "metadata": {},
   "source": [
    "# Upload Obsidian vault files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d00bb4",
   "metadata": {},
   "source": [
    "#### Using Obsidian reader from LLama Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d414a6d-46da-43dd-ad82-44f404c86ae1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id_='e0bd37fc-c7c6-498b-bb0e-3ed6bd7fd1c4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Quels critères pour dire que des données sont de qualité ?\\n- Exactitude : les données sont justes et cohérentes\\n- Complétude : le jeu de données est complet \\n- Pertinence : les données que l'on a sont elles pertinentes pour répondre à nos besoins (et par extension ceux du client ?)\\n\\nDes données de bonnes qualités sont essentielles pour avoir des donnes fiables \", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='17355f17-5624-4ba3-9cce-e07324d93d17', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Ensemble des opérations pour rendre les [[données]] utilisables, notamment : \\n- Nettoyage : correction des erreurs\\n- Normalisation : uniformisation des formats\\n- Transformation : restructuration pour les adapter aux outils de visualisation\\n\\n\\n#concept ', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='25c589d8-7305-4f74-812d-b47f8a26b536', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='---\\npartie de:\\n  - \"[[Dataviz Project]]\"\\n  - \"[[dataviz]]\"\\n---\\nA chaque visualisation de données correspond un certain [[Input]], c\\'est à dire une certaine structure de données. The [[Dataviz Project]] montre à voir la relation entre les inputs et les visualisations de données. \\n\\n', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='6ee3de3f-817b-4d37-9294-be4948123873', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Attention c'est un gros mot \\nLes 3V \\n- Volume : quantité massive de données\\n- Vélocité : vitesse de génération de ces données\\n- Variétés : diversité du type de données \\n\\nExemple : les flux des [[Réseaux sociaux]]\", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='878d7725-90fe-42cb-9db7-bad9ba51eaec', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='\\nSystème organisé pour stocker, gérer et récupérer des données \\nEssentielles pour gérer les données efficacement et permettre des requêtes rapides\\n\\n- [[Base de données relationnelles]] : [[Données structurées]], avec des relations entre les tables\\n- [[Base de données non relationnelles]] : plus flexibles, adaptées aux [[Données non structurées]]\\n\\n\\n', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='fa9b23bc-793b-42c8-ae40-c58e3a0859d7', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Tirer des conclusions ou des insights à partir des [[données]]. \\nOu comment passer de l'observation d'un graphique à l'interprétation des tendances ou des corrélations\\n\\n#concept \", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='51bb6572-3456-45a8-a7f8-2b7be388ddb1', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"La data visualisation consiste à transformer des données brutes en graphiques, diagrammes ou infographies pour rendre l'information claire et compréhensible.\\n\\nC'est une manière de rendre accessible des données à un public varié.\\nCela permet aussi de faciliter la prise de décision. \\n\", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='7eabbcca-f182-4f01-886f-477f192e3186', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='\\n\\nListe de concepts\\n```dataview\\nLIST \\nFROM #concept\\n```\\n', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='79dc4eed-48f5-4da4-8b13-d0ed1e329be9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Processus de préparation des [[données]] pour les rendre exploitables\\n- Supprimer ou corriger les données inexactes ou les doublons\\n- Remplir les données manquantes\\n- Uniformiser les formats (dates)', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='d33b0621-9e96-473b-8756-8b3827515401', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Comprendre l\\'objectif de la visualisation. Avoir une première idée de ce que l\\'on cherche à représenter, ce que l\\'on cherche à communiquer \\n\\nPar exemple : \\n- Identifier des tendances,\\n- présenter des comparaisons,\\n- expliquer un phénomène \\n\\nQui est le public cible de ma visualisation ? \\n- experts\\n- collègues (à l\\'intérieur d\\'une entreprise)\\n- vers l\\'extérieur (\"\"\"\"\"le public\"\"\"\"\")\\n\\nQuel est le message qui doit ressrotir ', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='ffc080f0-00c1-4a67-8970-29cd704fff75', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='> Perso, ce qui m\\'emmerde au quotidien c\\'est qu\\'on me balance des données à la gueule et on me dit \"allez, fais moi une synthèse graphique\" et je suis paumé\\n\\n\\n\\nQue faire quand on se retrouve face à une montagne de [[données]]\\nQuels sont les [[outils]] à disposition ? \\nQuelles sont les bonnes pratiques pour réceptionner, gérer et exploiter des données ? \\n\\n\\nQuelle est la part d\\'adaptation que l\\'on peut offrir quand on se retrouve face à quelque chose d\\'aussi rigoureux que la manipulation de données ?\\n\\nPour moi (théophile) : la question de la donnée est intrinsèquement liée à la question de l\\'outil informatique puisque c\\'est comme ça qu\\'on la manipule aujourd\\'hui. Mais il y a aussi quelque chose de vertigineux dans le fait que l\\'outil avec lequel on manipule nos données (un ordinateur) manipule lui même une quantité de données phénoménales.\\n\\nLa donnée des uns sera-t-elle la donnée des autres ? \\nComment assurer une transmission de la donnée ? \\nEst-ce tout le point de la dataviz ? \\n\\nDans la question de la dataviz et de son but il y a la question de l\\'interaction entre l\\'homme et la donnée \\n\\n', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='433b4ae1-9caf-416d-a164-b2330eb95853', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"\\nPhase d'analyse des [[données|données]] pour comprendre leur structure, détecter les anomalies ou les tendances et guider le choix des visualisations. \\n\\n\\n#concept \", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='ef020d0f-cafa-4d1b-9458-b74048868a68', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='\\nManière dont les utilisateurs interprètent les données au travers de la visualisation\\n\\n#concept ', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='8048610e-e4f6-4ab5-bfd3-1569029af164', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"\\nLes données telles qu'elles sont collectées à la source, souvent désorganisées, incomplètes ou avec des erreurs. Elles nécessites un [[Traitement des données |traitement]] avant d'être visualisées\\n\\n\\n#concept\\n\", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='666e729b-584a-401d-9f71-4856f685f9d9', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"\\nLes [[dataviz]] produitent reflètent-elles fidèlement les données d'[[Input]]\\nLe message est-il clair pour le public cible ?\\n\\n**Tester** avec des parties prenantes pour recueillir des retours\\nApporter des modifications si nécessaires\\n\\n\", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='e98bca10-b57b-4ee6-a0fb-eb5d7125f5ae', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Ajout d'éléments dynamiques pour permettre aux [[utilisateur]]s d'explorer les [[données]] de différentes manières\\nPermet de créer une relation à la donnée \\n\\nExemple : \\n- Gérer des filtres\\n- Pouvoir afficher des détails\\n- Avoir accès à différents niveaux d'informations, ou gérer qui peut avoir accès à quel niveau d'information \\n\\n#concept \", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='b3e08cda-3a31-4794-b63d-377a1d0b7674', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"---\\nurl: https://datavizproject.com/\\n---\\nDataviz project est une bibliothèque de type de graphs\\nOn y retrouve une description, des informations sur l'input nécessaire, des exemples de réalisation...\\n\\n---\\n[[dataviz]]\", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='b7d4b08d-b1a5-40e8-a7ac-7a1a3aed33f3', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='\\nMaximum\\nMinimum\\nMoyenne \\nMédiane\\nÉcart-type\\nQuartiles', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='ef7b43b0-cfde-4d1e-8d11-56984b7bc641', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"\\nDonnées qui n'ont pas de format prédéfini ou organisé. Elles peuvent contenir du texte libre, des images, des vidéos ou des documents. \\nPar exemple : des mails, des enregistrements audio ou du contenu en flux sur les réseaux sociaux. \\nPour les interpréter il faut des outils spécialisés comme le traitement du langage naturel ou la reconnaissance d'image pour être analysées.****\", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='7deb552b-0b33-4135-b50c-589f17c65f5d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Réflexion à mener sur la figure de l'utilisateur dans le parcours par rapport aux données ? \\n\\nRetrouver le schéma dataviz : que faire si je me retrouve face à un jeu de données \\nEst ce que c'est quelque chose que le LLM peut lire ? \", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='2a424619-b475-4309-bf22-3ebdd4250a3a', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Art de raconter une histoire avec des [[données]] \\nImplique de : \\n- Sélectionner les bonnes visualisatoin\\n- Mettre en évidence les messages clés\\n- Utiliser des annotations ou du texte pour guider l'[[utilisateur]] dans l'interprétation\", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='72802396-db0c-47e1-af7e-b853fbf78a27', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='#concept \\n', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='c69d0726-7d72-4eef-a78a-3537c67a8c89', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Données sur les [[données]]\\nPermet de décrire les caractéristiques ou le contexte d'un jeu de données. \\nPar exemple : pour une photo, les métadonnées incluent la date de la prise de vue, la résolution, le lieu \\nElles permettent d'aider à organiser les informations que l'on a\\n\", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='641f3cb5-60e6-437d-9445-3485ccfdadfc', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"[[données]] organisées de manière claire et standardisée\\nOn les retrouve le plus souvent dans un tableau ([[spreadsheet]]) donc avec des lignes et des colonnes \\n\\nC'est ce qu'on retrouve dans les bases de données relationnelles => chaque colonne est définie avec un nom et un type de données, on peut identifier la relation entre les différentes données par un identifiant unique dénominateur commun.\\n\\nLes données structurées sont faciles à interroger avec des outils comme SQL\", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='4baacbd3-c958-4bc6-b8c0-496c0b05ad52', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Tout n'est que données \\nL'art de la [[dataviz]] c'est de transformer un tas de trucs qu'on sait pas trop comment définir en des connaissances et des idées et leur donner une application dans la vie courante.\\n\\n**Exemple :** Le service communication d'une entreprise analyse les données relatives à l'envoi d'une newsletter pour comprendre ce qui a mieux ou moins bien marché. Ils utilisent des outils qui mettent en forment les données et en produisent des évaluations, parfois même des interprétations.\\n\\nPour comprendre les données, on cherche à analyser les [[Inférence]]s et trouver des relation dans notre tas d'informations.\", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='cc34e192-50c6-469a-80c4-8a0f724d77e2', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='\\nEn fonction de la nature des données, on ne choisit pas les mêmes types de représentations \\nExemple : \\nPour une série temporelle, on utilisera un graphique en ligne\\nComparaisons entre plusieurs catégories on utilisera un diagramme à barre ou un camembert.\\n\\n**En fonction du message à communiquer :** \\nSi on a besoin de communiquer des tendances, on choisira plutôt des courbes\\nProportions : Diagrammes circulaires ou treemaps\\nRépartition : histogrammes ou boxplots ', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='35a5645f-ff94-4184-9ffd-88d71affdeb5', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Examiner les données fournies\\n- Quels sont les types de données (string, number, boolean, time)\\n- Est ce qu'il y a des valeurs anormales ou manquantes \\n\\nIdentifier la structure : \\n- Quelles sont les relations entre les données\\n- Avec combien de variables on joue\\n\\nExploration rapide :\\n- Quelques [[statistiques descriptives]] (moyenne, médiane, écart-type....)\\n- \", mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='21d9ed9e-7ab1-46fa-8464-52143b4e7f54', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Créer des visualisations compréhensibles et utilisables par tout le monde ([[utilisateur]]), y compris les personnes avec un handicap.\\n \\n \\n #concept ', mimetype=None, path=None, url=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]\n"
     ]
    }
   ],
   "source": [
    "#locate obsidian files that make your graph\n",
    "filepath = r\"/Users/arthursarazin/Documents/coreandgraphs/graphandvisualize/graph\"\n",
    "\n",
    "#load the graph files \n",
    "graph_files = ObsidianReader(filepath).load_data()\n",
    "print(list(graph_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4066792",
   "metadata": {},
   "source": [
    "# Using manual code to create specific ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f92a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les métadonnées YAML et le titre d'un fichier Markdown\n",
    "def extract_metadata_and_title(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        # Recherchez la section YAML (entre `---` au début et à la fin)\n",
    "        if content.startswith(\"---\"):\n",
    "            try:\n",
    "                yaml_block = content.split(\"---\", 2)[1]\n",
    "                metadata = yaml.safe_load(yaml_block)\n",
    "                return os.path.basename(file_path).replace(\".md\", \"\"), metadata\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de l'extraction des métadonnées de {file_path}: {e}\")\n",
    "                return None, None\n",
    "        return os.path.basename(file_path).replace(\".md\", \"\"), None\n",
    "\n",
    "# Parcourir les fichiers Obsidian et créer des entités et relations\n",
    "def process_obsidian_notes(directory):\n",
    "    entities = []\n",
    "    relations = []\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".md\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                title, metadata = extract_metadata_and_title(file_path)\n",
    "                if title:\n",
    "                    # Ajouter l'entité basée sur le titre\n",
    "                    entities.append({\"name\": title})\n",
    "                    \n",
    "                    # Ajouter les relations basées sur les propriétés YAML\n",
    "                    if metadata:\n",
    "                        for key, value in metadata.items():\n",
    "                            relations.append({\n",
    "                                \"type\": key,  # Nom de la propriété comme relation\n",
    "                                \"source\": title,  # Titre du fichier comme entité source\n",
    "                                \"target\": value,  # Valeur de la propriété comme entité cible\n",
    "                            })\n",
    "    return entities, relations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95381307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation\n",
    "obsidian_dir = r\"C:\\Users\\asarazin\\OneDrive - Veltys Max\\Documents\\documente-marcel\\graph\"\n",
    "entities, relations = process_obsidian_notes(obsidian_dir)\n",
    "\n",
    "print(relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5efb9f-d02f-490e-966c-f490b5e9db3e",
   "metadata": {},
   "source": [
    "# Set LLM (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f70c5fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/arthursarazin/anaconda3/lib/python3.11/site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b597ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()  # Charge les variables depuis le fichier .env\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY_UP\")\n",
    "print(api_key)\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66762fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a30f2c04-d01b-47ce-a532-c6c8fb4ee42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-4o\", max_tokens=3000)\n",
    "Settings.llm = llm\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a010330-bc6a-4e1c-8605-16afe8200585",
   "metadata": {},
   "source": [
    "# Set local LLM for embeddings ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa6be1f9-b33d-400a-a471-eeeeb35c0448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "Load pretrained SentenceTransformer: BAAI/bge-base-en-v1.5\n",
      "INFO:sentence_transformers.SentenceTransformer:2 prompts are loaded, with the keys: ['query', 'text']\n",
      "2 prompts are loaded, with the keys: ['query', 'text']\n"
     ]
    }
   ],
   "source": [
    "# bge-base embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "#Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e871d-dbf8-4cb1-897d-bdaef21b170d",
   "metadata": {},
   "source": [
    "# Set LLM for chat  (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5843a4c5-e11f-4c32-b446-2aec529a5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = Ollama(model=\"tinyllama\", request_timeout=120.0)\n",
    "#Settings.llm = llm\n",
    "#Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c5460a-bb6d-4839-92db-1180e146af06",
   "metadata": {},
   "source": [
    "# Test LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a1e0de1-14c5-4b4b-9e40-ebbdae50b263",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************mY4A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     ChatMessage(\n\u001b[1;32m      3\u001b[0m         role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a data governance consultant\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     ),\n\u001b[1;32m      5\u001b[0m     ChatMessage(role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms your favorite data tool ?\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m ]\n\u001b[0;32m----> 7\u001b[0m resp \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mchat(messages)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(resp)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:321\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[0;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[1;32m    324\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/core/llms/callbacks.py:173\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[0;34m(_self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m event_id \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_event_start(\n\u001b[1;32m    165\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    166\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m     },\n\u001b[1;32m    171\u001b[0m )\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     f_return_val \u001b[38;5;241m=\u001b[39m f(_self, messages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    175\u001b[0m     callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[1;32m    176\u001b[0m         CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[1;32m    177\u001b[0m         payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mEXCEPTION: e},\n\u001b[1;32m    178\u001b[0m         event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[1;32m    179\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/openai/base.py:355\u001b[0m, in \u001b[0;36mOpenAI.chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     chat_fn \u001b[38;5;241m=\u001b[39m completion_to_chat_decorator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_complete)\n\u001b[0;32m--> 355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m chat_fn(messages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/openai/base.py:106\u001b[0m, in \u001b[0;36mllm_retry_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     99\u001b[0m retry \u001b[38;5;241m=\u001b[39m create_retry_decorator(\n\u001b[1;32m    100\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    101\u001b[0m     random_exponential\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m     max_seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m    105\u001b[0m )\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry(f)(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m fut\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fut\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fut\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/openai/base.py:432\u001b[0m, in \u001b[0;36mOpenAI._chat\u001b[0;34m(self, messages, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m message_dicts \u001b[38;5;241m=\u001b[39m to_openai_message_dicts(\n\u001b[1;32m    427\u001b[0m     messages,\n\u001b[1;32m    428\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    429\u001b[0m )\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreuse_client:\n\u001b[0;32m--> 432\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    433\u001b[0m         messages\u001b[38;5;241m=\u001b[39mmessage_dicts,\n\u001b[1;32m    434\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[1;32m    436\u001b[0m     )\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m client:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_utils/_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/resources/chat/completions.py:859\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    856\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    857\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    858\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    860\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    861\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[1;32m    862\u001b[0m             {\n\u001b[1;32m    863\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    864\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    865\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[1;32m    866\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m    867\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m    868\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m    869\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m    870\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m    871\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m    872\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m    873\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    874\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[1;32m    875\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m    876\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m    877\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[1;32m    878\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m    879\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[1;32m    880\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    881\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m    882\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m    883\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m    884\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m    885\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m    886\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m    887\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    888\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m    889\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    890\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m    891\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    892\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m    893\u001b[0m             },\n\u001b[1;32m    894\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m    895\u001b[0m         ),\n\u001b[1;32m    896\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    897\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    898\u001b[0m         ),\n\u001b[1;32m    899\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m    900\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    901\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[1;32m    902\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1279\u001b[0m     )\n\u001b[0;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    958\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    959\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    960\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    961\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    962\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m    963\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1070\u001b[0m )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************mY4A. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a data governance consultant\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What's your favorite data tool ?\"),\n",
    "]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee83593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate vector store\n",
    "simple_glossary = SimpleDirectoryReader(\n",
    "    r\"/Users/arthursarazin/Documents/coreandgraphs/graphandvisualize/graph\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b83af3-ff18-40f0-8469-5c8b2a75b5dd",
   "metadata": {},
   "source": [
    "# Instantiate graph store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e12d5f9c-03ea-4af6-a3ad-c1764d08e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store = SimpleGraphStore()\n",
    "graph_storage_context = StorageContext.from_defaults(graph_store=graph_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f102bb",
   "metadata": {},
   "source": [
    "# Instantiate ontology store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a66387e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_store = SimpleGraphStore()\n",
    "onto_storage_context = StorageContext.from_defaults(graph_store=onto_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94eacca-42e3-4140-a620-c199f3578e6e",
   "metadata": {},
   "source": [
    "# Construct Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a821e-abd8-4cb4-b2dc-98163aa332df",
   "metadata": {},
   "source": [
    "## Construct Vector Store Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fee7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents = simple_glossary.load_data(),\n",
    "    show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c8c116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index to disk\n",
    "vector_index.set_index_id(\"vector_index\")\n",
    "vector_index.storage_context.persist(\"vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6061a476-f5cc-4805-ad25-6e1533e787e5",
   "metadata": {},
   "source": [
    "## Construct knowledge graph index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "250b454a-f598-4749-8847-f59fa3a36a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(doc):\n",
    "    # This function will be called for each document\n",
    "    print(f\"Processing document: {doc.doc_id}\")\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca242f4-8ce0-4599-a888-eccc840b1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your graph files loaded\n",
    "print(f\"Starting to process {len(graph_files)} documents...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73397fd8-2bb8-41c3-ae12-f64621c9fa54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Wrap your document processing in a progress bar\n",
    "graph_index = KnowledgeGraphIndex.from_documents(\n",
    "        documents=[process_document(doc) for doc in graph_files],  # process one document at a time\n",
    "        max_triplets_per_chunk=2,\n",
    "        storage_context=graph_storage_context,\n",
    "        include_embeddings=True,\n",
    "    show_progress=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf91f91-dfe7-4034-8719-54b10a1d1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e2e5de7-68d1-4b89-b1c2-e703f31419d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_index.set_index_id(\"graph_index\")\n",
    "graph_index.storage_context.persist(\"knowledge_graph\")\n",
    "graph_storage_context.persist(persist_dir=\"knowledge_graph\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48545d",
   "metadata": {},
   "source": [
    "## Construct knowledge with ontology as assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64c7bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_store = SimpleGraphStore()\n",
    "onto_storage_context = StorageContext.from_defaults(graph_store=onto_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76ed084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurer DynamicLLMPathExtractor avec les entités et relations extraites\n",
    "kg_extractor = DynamicLLMPathExtractor(\n",
    "    llm=llm,\n",
    "    max_triplets_per_chunk=20,\n",
    "    num_workers=4,\n",
    "    allowed_entity_types=None,  # Si vous ne limitez pas les types d'entités\n",
    "    allowed_relation_types=None,  # Si vous ne limitez pas les types de relations\n",
    "    allowed_entity_props=None,\n",
    "    allowed_relation_props=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0225a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Résumé des entités et relations extraites\n",
    "print(\"Entités :\")\n",
    "for entity in entities:\n",
    "    print(entity)\n",
    "\n",
    "print(\"\\nRelations :\")\n",
    "for relation in relations:\n",
    "    print(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e813096",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_index = PropertyGraphIndex.from_documents(\n",
    "    documents=[process_document(doc) for doc in graph_files],\n",
    "    llm=llm,\n",
    "    storage_context=onto_storage_context,\n",
    "    embed_kg_nodes=True,\n",
    "    kg_extractors=[kg_extractor],\n",
    "    show_progress=True,\n",
    "    graph_store=onto_store \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba268ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(onto_storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7314a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save index to disk\n",
    "onto_index.set_index_id(\"onto_index\")\n",
    "onto_index.storage_context.persist(\"onto_graph\")\n",
    "onto_storage_context.persist(persist_dir=\"onto_graph\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
